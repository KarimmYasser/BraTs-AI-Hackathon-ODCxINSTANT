{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SegResNet Inference and Visualization\n",
        "\n",
        "This notebook loads a pre-trained SegResNet model and performs inference on brain tumor MRI data.\n",
        "\n",
        "## Contents\n",
        "1. Imports and Setup\n",
        "2. SegResNet Model Architecture\n",
        "3. Load Pre-trained Model\n",
        "4. Inference Functions\n",
        "5. Visualization\n",
        "6. Generate Submission\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Imports and Setup\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. SegResNet Model Architecture\n",
        "\n",
        "The same architecture used during training must be defined here.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual block that learns the difference instead of raw mapping.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        \n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm3d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x += residual\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SegResNet(nn.Module):\n",
        "    \"\"\"SegResNet for volumetric segmentation.\"\"\"\n",
        "    def __init__(self, in_channels=4, out_channels=4, init_filters=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, init_filters, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(init_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.res_block1 = ResidualBlock(init_filters, init_filters)\n",
        "        self.res_block2 = ResidualBlock(init_filters, init_filters * 2, stride=2)\n",
        "        self.res_block3 = ResidualBlock(init_filters * 2, init_filters * 4, stride=2)\n",
        "        self.res_block4 = ResidualBlock(init_filters * 4, init_filters * 8, stride=2)\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.bottleneck = ResidualBlock(init_filters * 8, init_filters * 16, stride=2)\n",
        "        \n",
        "        # Decoder\n",
        "        self.up4 = nn.ConvTranspose3d(init_filters * 16, init_filters * 8, kernel_size=2, stride=2)\n",
        "        self.dec4 = ResidualBlock(init_filters * 16, init_filters * 8)\n",
        "        \n",
        "        self.up3 = nn.ConvTranspose3d(init_filters * 8, init_filters * 4, kernel_size=2, stride=2)\n",
        "        self.dec3 = ResidualBlock(init_filters * 8, init_filters * 4)\n",
        "        \n",
        "        self.up2 = nn.ConvTranspose3d(init_filters * 4, init_filters * 2, kernel_size=2, stride=2)\n",
        "        self.dec2 = ResidualBlock(init_filters * 4, init_filters * 2)\n",
        "        \n",
        "        self.up1 = nn.ConvTranspose3d(init_filters * 2, init_filters, kernel_size=2, stride=2)\n",
        "        self.dec1 = ResidualBlock(init_filters * 2, init_filters)\n",
        "        \n",
        "        self.final = nn.Conv3d(init_filters, out_channels, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1 = self.enc1(x)\n",
        "        x1 = self.res_block1(x1)\n",
        "        x2 = self.res_block2(x1)\n",
        "        x3 = self.res_block3(x2)\n",
        "        x4 = self.res_block4(x3)\n",
        "        \n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(x4)\n",
        "        \n",
        "        # Decoder with skip connections\n",
        "        u4 = self.up4(b)\n",
        "        if u4.shape != x4.shape:\n",
        "            u4 = F.interpolate(u4, size=x4.shape[2:])\n",
        "        d4 = torch.cat((u4, x4), dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "        \n",
        "        u3 = self.up3(d4)\n",
        "        if u3.shape != x3.shape:\n",
        "            u3 = F.interpolate(u3, size=x3.shape[2:])\n",
        "        d3 = torch.cat((u3, x3), dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "        \n",
        "        u2 = self.up2(d3)\n",
        "        if u2.shape != x2.shape:\n",
        "            u2 = F.interpolate(u2, size=x2.shape[2:])\n",
        "        d2 = torch.cat((u2, x2), dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "        \n",
        "        u1 = self.up1(d2)\n",
        "        if u1.shape != x1.shape:\n",
        "            u1 = F.interpolate(u1, size=x1.shape[2:])\n",
        "        d1 = torch.cat((u1, x1), dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "        \n",
        "        return self.final(d1)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Load Pre-trained Model\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"/kaggle/input/segresnet-checkpoint/segresnet_best.pth\"\n",
        "\n",
        "# Initialize model\n",
        "model = SegResNet(in_channels=4, out_channels=4, init_filters=32).to(DEVICE)\n",
        "\n",
        "# Load weights\n",
        "try:\n",
        "    state_dict = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(state_dict)\n",
        "    print(\"Model weights loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading weights: {e}\")\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Inference Functions\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_volume(volume):\n",
        "    \"\"\"Robust Z-Score Normalization.\"\"\"\n",
        "    mask = volume > 0\n",
        "    if np.sum(mask) == 0:\n",
        "        return volume\n",
        "\n",
        "    pixels = volume[mask]\n",
        "    p_low, p_high = np.percentile(pixels, 0.5), np.percentile(pixels, 99.5)\n",
        "    volume = np.clip(volume, p_low, p_high)\n",
        "    \n",
        "    pixels = volume[mask]\n",
        "    mean, std = pixels.mean(), pixels.std()\n",
        "    volume = (volume - mean) / (std + 1e-8)\n",
        "    volume[~mask] = 0\n",
        "    \n",
        "    return volume\n",
        "\n",
        "\n",
        "def sliding_window_inference(model, image, patch_size=(96, 96, 96), overlap=0.5):\n",
        "    \"\"\"Sliding window inference for large 3D volumes.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    batch_size = image.shape[0]\n",
        "    image_size = image.shape[2:]\n",
        "    \n",
        "    output_probs = torch.zeros((batch_size, 4, *image_size), device=image.device, dtype=torch.float32)\n",
        "    count_map = torch.zeros((batch_size, 4, *image_size), device=image.device, dtype=torch.float32)\n",
        "    \n",
        "    step = [int(p * (1 - overlap)) for p in patch_size]\n",
        "    \n",
        "    for z in range(0, image_size[0] - patch_size[0] + 1, step[0]):\n",
        "        for y in range(0, image_size[1] - patch_size[1] + 1, step[1]):\n",
        "            for x in range(0, image_size[2] - patch_size[2] + 1, step[2]):\n",
        "                patch = image[:, :, z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]]\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "                        pred = model(patch)\n",
        "                        pred = F.softmax(pred, dim=1)\n",
        "                \n",
        "                output_probs[:, :, z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]] += pred\n",
        "                count_map[:, :, z:z+patch_size[0], y:y+patch_size[1], x:x+patch_size[2]] += 1\n",
        "    \n",
        "    output_probs /= count_map.clamp(min=1)\n",
        "    return output_probs\n",
        "\n",
        "\n",
        "def simple_resize_inference(model, image, target_size=(96, 96, 96)):\n",
        "    \"\"\"Simple resize-based inference for faster processing.\"\"\"\n",
        "    model.eval()\n",
        "    original_shape = image.shape[2:]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        small_image = F.interpolate(image, size=target_size, mode='trilinear', align_corners=False)\n",
        "        \n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "            pred = model(small_image)\n",
        "        \n",
        "        pred = F.interpolate(pred, size=original_shape, mode='trilinear', align_corners=False)\n",
        "        pred = F.softmax(pred, dim=1)\n",
        "    \n",
        "    return pred"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Visualization\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_test_prediction(model, test_path, patient_id=None):\n",
        "    \"\"\"Visualize the model's prediction for a test patient.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    if patient_id is None:\n",
        "        patients = sorted([p for p in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, p))])\n",
        "        if len(patients) == 0:\n",
        "            print(\"No patients found!\")\n",
        "            return\n",
        "        patient_id = patients[0]\n",
        "    \n",
        "    patient_path = os.path.join(test_path, patient_id)\n",
        "    print(f\"Processing patient: {patient_id}\")\n",
        "    \n",
        "    # Load modalities\n",
        "    modalities = {}\n",
        "    for f in os.listdir(patient_path):\n",
        "        if f.endswith('.nii.gz'):\n",
        "            for mod in ['t1ce', 't1', 't2', 'flair']:\n",
        "                if mod in f.lower():\n",
        "                    if mod == 't1' and 't1ce' in f.lower():\n",
        "                        continue\n",
        "                    modalities[mod] = nib.load(os.path.join(patient_path, f)).get_fdata()\n",
        "                    break\n",
        "    \n",
        "    # Normalize and stack\n",
        "    image = np.stack([\n",
        "        normalize_volume(modalities['t1'].astype(np.float32)),\n",
        "        normalize_volume(modalities['t1ce'].astype(np.float32)),\n",
        "        normalize_volume(modalities['t2'].astype(np.float32)),\n",
        "        normalize_volume(modalities['flair'].astype(np.float32))\n",
        "    ], axis=0)\n",
        "    \n",
        "    # Inference\n",
        "    image_tensor = torch.from_numpy(image).unsqueeze(0).to(DEVICE)\n",
        "    probs = simple_resize_inference(model, image_tensor)\n",
        "    prediction = torch.argmax(probs, dim=1).squeeze().cpu().numpy()\n",
        "    \n",
        "    # Find slice with most tumor\n",
        "    tumor_per_slice = [(prediction[:, :, z] > 0).sum() for z in range(prediction.shape[2])]\n",
        "    best_slice = np.argmax(tumor_per_slice)\n",
        "    \n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    \n",
        "    axes[0].imshow(np.rot90(modalities['t1'][:, :, best_slice]), cmap='gray')\n",
        "    axes[0].set_title('T1')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(np.rot90(modalities['t1ce'][:, :, best_slice]), cmap='gray')\n",
        "    axes[1].set_title('T1ce')\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    axes[2].imshow(np.rot90(modalities['t2'][:, :, best_slice]), cmap='gray')\n",
        "    axes[2].set_title('T2')\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    axes[3].imshow(np.rot90(modalities['flair'][:, :, best_slice]), cmap='gray')\n",
        "    axes[3].set_title('FLAIR')\n",
        "    axes[3].axis('off')\n",
        "    \n",
        "    cmap = mcolors.ListedColormap(['black', 'red', 'green', 'yellow'])\n",
        "    axes[4].imshow(np.rot90(prediction[:, :, best_slice]), cmap=cmap, vmin=0, vmax=3)\n",
        "    axes[4].set_title('Prediction')\n",
        "    axes[4].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"Patient: {patient_id} | Slice: {best_slice}\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "TEST_PATH = \"/kaggle/input/instant-odc-ai-hackathon/test\"\n",
        "# visualize_test_prediction(model, TEST_PATH)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. Generate Submission\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_encode(mask):\n",
        "    \"\"\"Encode binary mask to Run-Length Encoding.\"\"\"\n",
        "    pixels = mask.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "def generate_submission(model, test_path, output_path=\"submission.csv\"):\n",
        "    \"\"\"Generate submission CSV with RLE-encoded predictions.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    submission_rows = []\n",
        "    patients = sorted([p for p in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, p))])\n",
        "    \n",
        "    for patient_id in tqdm(patients, desc=\"Processing\"):\n",
        "        patient_path = os.path.join(test_path, patient_id)\n",
        "        \n",
        "        modalities = {}\n",
        "        for f in os.listdir(patient_path):\n",
        "            if f.endswith('.nii.gz'):\n",
        "                for mod in ['t1ce', 't1', 't2', 'flair']:\n",
        "                    if mod in f.lower():\n",
        "                        if mod == 't1' and 't1ce' in f.lower():\n",
        "                            continue\n",
        "                        modalities[mod] = nib.load(os.path.join(patient_path, f)).get_fdata()\n",
        "                        break\n",
        "        \n",
        "        if len(modalities) < 4:\n",
        "            continue\n",
        "        \n",
        "        image = np.stack([\n",
        "            normalize_volume(modalities['t1'].astype(np.float32)),\n",
        "            normalize_volume(modalities['t1ce'].astype(np.float32)),\n",
        "            normalize_volume(modalities['t2'].astype(np.float32)),\n",
        "            normalize_volume(modalities['flair'].astype(np.float32))\n",
        "        ], axis=0)\n",
        "        \n",
        "        image_tensor = torch.from_numpy(image).unsqueeze(0).to(DEVICE)\n",
        "        probs = simple_resize_inference(model, image_tensor)\n",
        "        prediction = torch.argmax(probs, dim=1).squeeze().cpu().numpy()\n",
        "        \n",
        "        wt_mask = (prediction > 0).astype(np.uint8)\n",
        "        tc_mask = ((prediction == 1) | (prediction == 3)).astype(np.uint8)\n",
        "        et_mask = (prediction == 3).astype(np.uint8)\n",
        "        \n",
        "        submission_rows.append({'id': f'{patient_id}_WT', 'rle': rle_encode(wt_mask)})\n",
        "        submission_rows.append({'id': f'{patient_id}_TC', 'rle': rle_encode(tc_mask)})\n",
        "        submission_rows.append({'id': f'{patient_id}_ET', 'rle': rle_encode(et_mask)})\n",
        "    \n",
        "    df = pd.DataFrame(submission_rows)\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"Submission saved to {output_path}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# Generate submission\n",
        "# df = generate_submission(model, TEST_PATH)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}