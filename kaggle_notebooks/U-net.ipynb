{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3D U-Net for Brain Tumor Segmentation\n",
        "\n",
        "This notebook implements a complete training pipeline for brain tumor segmentation using the BraTS 2021 dataset with a 3D U-Net architecture.\n",
        "\n",
        "## Contents\n",
        "1. Imports and Setup\n",
        "2. Data Loading\n",
        "3. Data Preprocessing\n",
        "4. Dataset and DataLoader\n",
        "5. Loss Functions\n",
        "6. 3D U-Net Model Architecture\n",
        "7. Training Loop\n",
        "8. Inference and Visualization\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Imports and Setup\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Data Loading\n",
        "\n",
        "Load the BraTS 2021 dataset and create a DataFrame with file paths.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/kaggle/temp/brats_extracted\"\n",
        "\n",
        "def get_brats_file_paths(root_dir):\n",
        "    \"\"\"Index all patient folders and return a DataFrame with file paths.\"\"\"\n",
        "    data_list = []\n",
        "    \n",
        "    if not os.path.exists(root_dir):\n",
        "        print(\"Error: Directory not found.\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Handle nested directory structure\n",
        "    search_dirs = [root_dir]\n",
        "    for item in os.listdir(root_dir):\n",
        "        item_path = os.path.join(root_dir, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            search_dirs.append(item_path)\n",
        "    \n",
        "    for search_dir in search_dirs:\n",
        "        for patient in os.listdir(search_dir):\n",
        "            patient_path = os.path.join(search_dir, patient)\n",
        "            if not os.path.isdir(patient_path):\n",
        "                continue\n",
        "            \n",
        "            # Find modality files\n",
        "            files = os.listdir(patient_path)\n",
        "            paths = {'id': patient}\n",
        "            \n",
        "            for modality in ['flair', 't1', 't1ce', 't2', 'seg']:\n",
        "                for f in files:\n",
        "                    if modality == 't1' and 't1ce' in f:\n",
        "                        continue\n",
        "                    if f.endswith('.nii.gz') and modality in f.lower():\n",
        "                        paths[modality] = os.path.join(patient_path, f)\n",
        "                        break\n",
        "            \n",
        "            if len(paths) == 6:\n",
        "                data_list.append(paths)\n",
        "    \n",
        "    print(f\"Found {len(data_list)} patients\")\n",
        "    return pd.DataFrame(data_list)\n",
        "\n",
        "df = get_brats_file_paths(DATA_ROOT)\n",
        "print(df.head())"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Data Preprocessing\n",
        "\n",
        "Functions for volume normalization, cropping, and patch extraction.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_volume(volume):\n",
        "    \"\"\"\n",
        "    Robust Z-Score Normalization.\n",
        "    Clips outliers and normalizes only non-zero (brain) region.\n",
        "    \"\"\"\n",
        "    mask = volume > 0\n",
        "    if np.sum(mask) == 0:\n",
        "        return volume\n",
        "\n",
        "    pixels = volume[mask]\n",
        "    p_low, p_high = np.percentile(pixels, 0.5), np.percentile(pixels, 99.5)\n",
        "    volume = np.clip(volume, p_low, p_high)\n",
        "    \n",
        "    pixels = volume[mask]\n",
        "    mean, std = pixels.mean(), pixels.std()\n",
        "    volume = (volume - mean) / (std + 1e-8)\n",
        "    volume[~mask] = 0\n",
        "    \n",
        "    return volume\n",
        "\n",
        "\n",
        "def crop_to_bbox(image_stack, label):\n",
        "    \"\"\"Crop to the bounding box of non-zero signal.\"\"\"\n",
        "    mask = np.sum(image_stack, axis=0) > 0\n",
        "    coords = np.argwhere(mask)\n",
        "    \n",
        "    if len(coords) == 0:\n",
        "        return image_stack, label\n",
        "\n",
        "    x_min, y_min, z_min = coords.min(axis=0)\n",
        "    x_max, y_max, z_max = coords.max(axis=0) + 1\n",
        "\n",
        "    return (image_stack[:, x_min:x_max, y_min:y_max, z_min:z_max], \n",
        "            label[x_min:x_max, y_min:y_max, z_min:z_max])\n",
        "\n",
        "\n",
        "def get_random_patch(image, label, patch_size=(128, 128, 128)):\n",
        "    \"\"\"Extract a random patch with foreground sampling.\"\"\"\n",
        "    c, h, w, d = image.shape\n",
        "    ph, pw, pd = patch_size\n",
        "\n",
        "    # Pad if smaller than patch\n",
        "    pad_h, pad_w, pad_d = max(ph-h, 0), max(pw-w, 0), max(pd-d, 0)\n",
        "    if pad_h or pad_w or pad_d:\n",
        "        image = np.pad(image, ((0, 0), (0, pad_h), (0, pad_w), (0, pad_d)), mode='constant')\n",
        "        label = np.pad(label, ((0, pad_h), (0, pad_w), (0, pad_d)), mode='constant')\n",
        "        h, w, d = image.shape[1:]\n",
        "\n",
        "    # Foreground sampling (33% chance)\n",
        "    if np.random.rand() < 0.33:\n",
        "        fg_coords = np.argwhere(label > 0)\n",
        "        if len(fg_coords) > 0:\n",
        "            center = fg_coords[np.random.randint(len(fg_coords))]\n",
        "            x = np.clip(center[0] - ph // 2, 0, h - ph)\n",
        "            y = np.clip(center[1] - pw // 2, 0, w - pw)\n",
        "            z = np.clip(center[2] - pd // 2, 0, d - pd)\n",
        "            return image[:, x:x+ph, y:y+pw, z:z+pd], label[x:x+ph, y:y+pw, z:z+pd]\n",
        "    \n",
        "    # Random sampling\n",
        "    x = np.random.randint(0, h - ph + 1)\n",
        "    y = np.random.randint(0, w - pw + 1)\n",
        "    z = np.random.randint(0, d - pd + 1)\n",
        "    \n",
        "    return image[:, x:x+ph, y:y+pw, z:z+pd], label[x:x+ph, y:y+pw, z:z+pd]"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Dataset and DataLoader\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class BratsDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for BraTS 2021 data.\"\"\"\n",
        "    def __init__(self, df, phase=\"train\", augment=False):\n",
        "        self.df = df\n",
        "        self.phase = phase\n",
        "        self.augment = augment\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        # Load and normalize each modality\n",
        "        t1 = normalize_volume(nib.load(row['t1']).get_fdata().astype(np.float32))\n",
        "        t1ce = normalize_volume(nib.load(row['t1ce']).get_fdata().astype(np.float32))\n",
        "        t2 = normalize_volume(nib.load(row['t2']).get_fdata().astype(np.float32))\n",
        "        flair = normalize_volume(nib.load(row['flair']).get_fdata().astype(np.float32))\n",
        "        seg = nib.load(row['seg']).get_fdata().astype(np.int64)\n",
        "        \n",
        "        # Remap labels: [0, 1, 2, 4] -> [0, 1, 2, 3]\n",
        "        seg[seg == 4] = 3\n",
        "        \n",
        "        # Stack modalities\n",
        "        image = np.stack([t1, t1ce, t2, flair], axis=0)\n",
        "        \n",
        "        # Crop and extract patch\n",
        "        image, seg = crop_to_bbox(image, seg)\n",
        "        image, seg = get_random_patch(image, seg, patch_size=(128, 128, 128))\n",
        "        \n",
        "        # Augmentation\n",
        "        if self.augment and self.phase == \"train\":\n",
        "            if np.random.rand() > 0.5:\n",
        "                image = np.flip(image, axis=1).copy()\n",
        "                seg = np.flip(seg, axis=0).copy()\n",
        "        \n",
        "        return torch.from_numpy(image), torch.from_numpy(seg)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(f\"Training: {len(train_df)}, Validation: {len(val_df)}\")\n",
        "\n",
        "# Create datasets and loaders\n",
        "BATCH_SIZE = 2\n",
        "train_ds = BratsDataset(train_df, phase=\"train\", augment=True)\n",
        "val_ds = BratsDataset(val_df, phase=\"val\", augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Loss Functions\n",
        "\n",
        "Dice Loss and Combined Dice-CrossEntropy Loss for segmentation.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Multi-class Dice Loss for segmentation.\"\"\"\n",
        "    def __init__(self, smooth=1e-5):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        probs = F.softmax(inputs, dim=1)\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=inputs.shape[1])\n",
        "        targets_one_hot = targets_one_hot.permute(0, 4, 1, 2, 3).float()\n",
        "\n",
        "        dims = (0, 2, 3, 4)\n",
        "        intersection = torch.sum(probs * targets_one_hot, dims)\n",
        "        cardinality = torch.sum(probs + targets_one_hot, dims)\n",
        "        \n",
        "        dice_score = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
        "        return 1. - dice_score.mean()\n",
        "\n",
        "\n",
        "class DiceCELoss(nn.Module):\n",
        "    \"\"\"Combined Dice and Cross-Entropy Loss.\"\"\"\n",
        "    def __init__(self, weight_ce=1.0, weight_dice=1.0):\n",
        "        super().__init__()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.weight_ce = weight_ce\n",
        "        self.weight_dice = weight_dice\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        loss_ce = self.ce(inputs, targets.long())\n",
        "        loss_dice = self.dice(inputs, targets)\n",
        "        return self.weight_ce * loss_ce + self.weight_dice * loss_dice"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. 3D U-Net Model Architecture\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"Double convolution block: (Conv3D -> InstanceNorm -> LeakyReLU) x 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.InstanceNorm3d(out_channels, affine=True),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.InstanceNorm3d(out_channels, affine=True),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downsampling with MaxPool followed by DoubleConv.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool3d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upsampling followed by DoubleConv with skip connection.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    \"\"\"3D U-Net for volumetric segmentation.\"\"\"\n",
        "    def __init__(self, in_channels=4, out_channels=4, features=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.inc = DoubleConv(in_channels, features)\n",
        "        self.down1 = Down(features, features * 2)\n",
        "        self.down2 = Down(features * 2, features * 4)\n",
        "        self.down3 = Down(features * 4, features * 8)\n",
        "        self.down4 = Down(features * 8, features * 16)\n",
        "        \n",
        "        # Decoder\n",
        "        self.up1 = Up(features * 16, features * 8)\n",
        "        self.up2 = Up(features * 8, features * 4)\n",
        "        self.up3 = Up(features * 4, features * 2)\n",
        "        self.up4 = Up(features * 2, features)\n",
        "        \n",
        "        # Output\n",
        "        self.outc = nn.Conv3d(features, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        \n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        \n",
        "        return self.outc(x)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7. Training Loop\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_brats_dice(predictions, masks):\n",
        "    \"\"\"Compute Dice Score for BraTS regions: WT, TC, ET.\"\"\"\n",
        "    preds_argmax = torch.argmax(predictions, dim=1)\n",
        "    \n",
        "    dice_scores = {'WT': 0.0, 'TC': 0.0, 'ET': 0.0}\n",
        "    batch_size = preds_argmax.shape[0]\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        pred = preds_argmax[i]\n",
        "        mask = masks[i]\n",
        "        \n",
        "        # Whole Tumor (WT): Labels 1, 2, 3\n",
        "        pred_wt = (pred > 0).float()\n",
        "        mask_wt = (mask > 0).float()\n",
        "        \n",
        "        # Tumor Core (TC): Labels 1, 3\n",
        "        pred_tc = ((pred == 1) | (pred == 3)).float()\n",
        "        mask_tc = ((mask == 1) | (mask == 3)).float()\n",
        "        \n",
        "        # Enhancing Tumor (ET): Label 3\n",
        "        pred_et = (pred == 3).float()\n",
        "        mask_et = (mask == 3).float()\n",
        "        \n",
        "        def dice(p, m, smooth=1e-5):\n",
        "            intersection = (p * m).sum()\n",
        "            return (2. * intersection + smooth) / (p.sum() + m.sum() + smooth)\n",
        "        \n",
        "        dice_scores['WT'] += dice(pred_wt, mask_wt).item()\n",
        "        dice_scores['TC'] += dice(pred_tc, mask_tc).item()\n",
        "        dice_scores['ET'] += dice(pred_et, mask_et).item()\n",
        "    \n",
        "    return {k: v / batch_size for k, v in dice_scores.items()}"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "EPOCHS = 20\n",
        "SAVE_PATH = \"unet3d_best.pth\"\n",
        "\n",
        "# Initialize\n",
        "model = UNet3D(in_channels=4, out_channels=4).to(DEVICE)\n",
        "criterion = DiceCELoss(weight_ce=1.0, weight_dice=1.0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    \n",
        "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for images, masks in progress:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        progress.set_postfix({\"loss\": loss.item()})\n",
        "    \n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    dice_wt, dice_tc, dice_et = 0.0, 0.0, 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, masks).item()\n",
        "            \n",
        "            dice = compute_brats_dice(outputs, masks)\n",
        "            dice_wt += dice['WT']\n",
        "            dice_tc += dice['TC']\n",
        "            dice_et += dice['ET']\n",
        "    \n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    dice_wt /= len(val_loader)\n",
        "    dice_tc /= len(val_loader)\n",
        "    dice_et /= len(val_loader)\n",
        "    \n",
        "    scheduler.step(avg_val_loss)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
        "    print(f\"         Dice WT={dice_wt:.4f}, TC={dice_tc:.4f}, ET={dice_et:.4f}\")\n",
        "    \n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"         Model saved!\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8. Inference and Visualization\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_prediction(model, loader, device=DEVICE):\n",
        "    \"\"\"Visualize model predictions alongside ground truth.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    images, masks = next(iter(loader))\n",
        "    images = images.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predictions = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
        "    \n",
        "    images = images.cpu().numpy()\n",
        "    masks = masks.numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    \n",
        "    sample_idx = 0\n",
        "    slice_idx = images.shape[4] // 2\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    \n",
        "    modalities = ['T1', 'T1ce', 'T2', 'FLAIR']\n",
        "    for i, name in enumerate(modalities):\n",
        "        axes[0, i].imshow(np.rot90(images[sample_idx, i, :, :, slice_idx]), cmap='gray')\n",
        "        axes[0, i].set_title(name)\n",
        "        axes[0, i].axis('off')\n",
        "    \n",
        "    axes[1, 0].imshow(np.rot90(masks[sample_idx, :, :, slice_idx]), cmap='jet', vmin=0, vmax=3)\n",
        "    axes[1, 0].set_title('Ground Truth')\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    axes[1, 1].imshow(np.rot90(predictions[sample_idx, :, :, slice_idx]), cmap='jet', vmin=0, vmax=3)\n",
        "    axes[1, 1].set_title('Prediction')\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    axes[1, 2].axis('off')\n",
        "    axes[1, 3].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize\n",
        "visualize_prediction(model, val_loader)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}