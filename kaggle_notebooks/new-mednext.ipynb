{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b97bd2",
   "metadata": {},
   "source": [
    "# MedNeXt Fine-Tuning (Differential Learning Rates)\n",
    "This notebook fine-tunes MedNeXt on BraTS-style data with a differential learning rate strategy, then provides training plots and inference loading helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30729bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:01:44.143347Z",
     "iopub.status.busy": "2026-02-03T17:01:44.142516Z",
     "iopub.status.idle": "2026-02-03T17:02:06.764067Z",
     "shell.execute_reply": "2026-02-03T17:02:06.763379Z",
     "shell.execute_reply.started": "2026-02-03T17:01:44.143309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mednext'...\n",
      "remote: Enumerating objects: 762, done.\u001b[K\n",
      "remote: Counting objects: 100% (320/320), done.\u001b[K\n",
      "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
      "remote: Total 762 (delta 270), reused 244 (delta 244), pack-reused 442 (from 1)\u001b[K\n",
      "Receiving objects: 100% (762/762), 522.43 KiB | 11.61 MiB/s, done.\n",
      "Resolving deltas: 100% (459/459), done.\n",
      "Obtaining file:///kaggle/working/mednext\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>1.10.0 in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (2.8.0+cu126)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (4.67.1)\n",
      "Collecting dicom2nifti (from mednextv1==1.7.0)\n",
      "  Downloading dicom2nifti-2.6.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (0.25.2)\n",
      "Collecting medpy (from mednextv1==1.7.0)\n",
      "  Downloading medpy-0.5.2.tar.gz (156 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (1.15.3)\n",
      "Collecting batchgenerators>=0.23 (from mednextv1==1.7.0)\n",
      "  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (1.6.1)\n",
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (2.5.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (2.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (2.32.5)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (5.3.2)\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (2025.10.16)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mednextv1==1.7.0) (3.10.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from batchgenerators>=0.23->mednextv1==1.7.0) (11.3.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from batchgenerators>=0.23->mednextv1==1.7.0) (1.0.0)\n",
      "Collecting unittest2 (from batchgenerators>=0.23->mednextv1==1.7.0)\n",
      "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.12/dist-packages (from batchgenerators>=0.23->mednextv1==1.7.0) (3.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.14->mednextv1==1.7.0) (3.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.14->mednextv1==1.7.0) (2.37.0)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.14->mednextv1==1.7.0) (26.0rc2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.14->mednextv1==1.7.0) (0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>1.10.0->mednextv1==1.7.0) (3.4.0)\n",
      "Requirement already satisfied: pydicom>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dicom2nifti->mednextv1==1.7.0) (3.0.1)\n",
      "Collecting python-gdcm (from dicom2nifti->mednextv1==1.7.0)\n",
      "  Downloading python_gdcm-3.2.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mednextv1==1.7.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mednextv1==1.7.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mednextv1==1.7.0) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mednextv1==1.7.0) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mednextv1==1.7.0) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mednextv1==1.7.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->mednextv1==1.7.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->mednextv1==1.7.0) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->mednextv1==1.7.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->mednextv1==1.7.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->mednextv1==1.7.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->mednextv1==1.7.0) (2026.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->mednextv1==1.7.0) (1.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mednextv1==1.7.0) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>1.10.0->mednextv1==1.7.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>1.10.0->mednextv1==1.7.0) (3.0.3)\n",
      "Collecting argparse (from unittest2->batchgenerators>=0.23->mednextv1==1.7.0)\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting traceback2 (from unittest2->batchgenerators>=0.23->mednextv1==1.7.0)\n",
      "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.23->mednextv1==1.7.0)\n",
      "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
      "Downloading dicom2nifti-2.6.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_gdcm-3.2.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: batchgenerators, medpy\n",
      "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=820c3deb22b733d9b7b213d44f245821116f8daa3c24e4fb635d259ebeed363d\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/21/2b/7b25080f9f5847e6c3162b89d859d7cec9f3093158e56bd008\n",
      "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for medpy: filename=MedPy-0.5.2-py3-none-any.whl size=224710 sha256=305e18a1c054adffb25dd19b9cd12f57953ca938be4d0acd836cf6a88f5d93ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/5a/f8/b3def53b9c2133d2f8698ea2173bb5df63bd8e761ce8e9aec9\n",
      "Successfully built batchgenerators medpy\n",
      "Installing collected packages: linecache2, argparse, traceback2, python-gdcm, unittest2, medpy, dicom2nifti, batchgenerators, mednextv1\n",
      "  Running setup.py develop for mednextv1\n",
      "Successfully installed argparse-1.4.0 batchgenerators-0.25.1 dicom2nifti-2.6.2 linecache2-1.0.0 mednextv1-1.7.0 medpy-0.5.2 python-gdcm-3.2.2 traceback2-1.4.0 unittest2-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MIC-DKFZ/MedNeXt.git mednext\n",
    "!pip install -e ./mednext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d744c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:06.765926Z",
     "iopub.status.busy": "2026-02-03T17:02:06.765659Z",
     "iopub.status.idle": "2026-02-03T17:02:11.501046Z",
     "shell.execute_reply": "2026-02-03T17:02:11.500280Z",
     "shell.execute_reply.started": "2026-02-03T17:02:06.765898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MedNeXt library imported successfully!\n",
      "============================================================\n",
      "ðŸ§  MEDNEXT-B FINE-TUNING WITH DIFFERENTIAL LEARNING RATES\n",
      "============================================================\n",
      "ðŸ“ Pretrained model: /kaggle/input/mednext/pytorch/default/1/best_model.pt\n",
      "ðŸ“ Training data:    /kaggle/input/instant-odc-ai-hackathon/Train\n",
      "ðŸ“ Output model:     /kaggle/working/best_finetuned_model.pt\n",
      "------------------------------------------------------------\n",
      "ðŸ”§ Model: MedNeXt-B (kernel=3)\n",
      "ðŸŽ¯ Strategy: Differential Learning Rates (all layers trainable)\n",
      "   â€¢ Early layers (stem, enc_0/1): 1.00e-06 (100x smaller)\n",
      "   â€¢ Later layers (enc_2+, decoder): 1.00e-04\n",
      "------------------------------------------------------------\n",
      "ðŸ“Š Epochs: 10\n",
      "ðŸ“Š Batch size: 1 per GPU\n",
      "ðŸ“Š Patch size: (128, 128, 128)\n",
      "ðŸ“Š Samples per volume: 4\n",
      "------------------------------------------------------------\n",
      "ðŸ“ˆ Warmup: 2 epochs (protects early training)\n",
      "ðŸ“ˆ Loss weights: Dice=1.0, CE=1.0\n",
      "------------------------------------------------------------\n",
      "ðŸ–¥ï¸ Device: cuda\n",
      "ðŸ–¥ï¸ GPUs available: 2\n",
      "ðŸš€ Multi-GPU training enabled with DataParallel!\n",
      "   Effective batch size: 2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "repo_path = os.path.abspath('mednext')\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "\n",
    "try:\n",
    "    from nnunet_mednext import create_mednext_v1, MedNeXt\n",
    "    print(\"MedNeXt library imported successfully.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing MedNeXt: {e}\")\n",
    "\n",
    "class TrainingConfig:\n",
    "    PRETRAINED_PATH = \"/kaggle/input/mednext/pytorch/default/1/best_model.pt\"\n",
    "    TRAIN_DIR = \"/kaggle/input/instant-odc-ai-hackathon/Train\"\n",
    "    OUTPUT_MODEL_PATH = \"/kaggle/working/best_finetuned_model.pt\"\n",
    "\n",
    "    MODEL_SIZE = 'B'\n",
    "    KERNEL_SIZE = 3\n",
    "    IN_CHANNELS = 4\n",
    "    NUM_CLASSES = 4\n",
    "\n",
    "    NUM_EPOCHS = 10\n",
    "    BATCH_SIZE = 1\n",
    "    PATCH_SIZE = (128, 128, 128)\n",
    "    SAMPLES_PER_VOLUME = 4\n",
    "    NUM_WORKERS = 4\n",
    "\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "\n",
    "    DICE_WEIGHT = 1.0\n",
    "    CE_WEIGHT = 1.0\n",
    "\n",
    "    WARMUP_EPOCHS = 2\n",
    "\n",
    "    VAL_SPLIT = 0.15\n",
    "\n",
    "    USE_AMP = True\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = TrainingConfig()\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MEDNEXT-B FINE-TUNING WITH DIFFERENTIAL LEARNING RATES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Pretrained model: {config.PRETRAINED_PATH}\")\n",
    "print(f\"Training data:    {config.TRAIN_DIR}\")\n",
    "print(f\"Output model:     {config.OUTPUT_MODEL_PATH}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Model: MedNeXt-{config.MODEL_SIZE} (kernel={config.KERNEL_SIZE})\")\n",
    "print(\"Strategy: Differential Learning Rates (all layers trainable)\")\n",
    "print(f\"   Early layers (stem, enc_0/1): {config.LEARNING_RATE * 0.01:.2e} (100x smaller)\")\n",
    "print(f\"   Later layers (enc_2+, decoder): {config.LEARNING_RATE:.2e}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Epochs: {config.NUM_EPOCHS}\")\n",
    "print(f\"Batch size: {config.BATCH_SIZE} per GPU\")\n",
    "print(f\"Patch size: {config.PATCH_SIZE}\")\n",
    "print(f\"Samples per volume: {config.SAMPLES_PER_VOLUME}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Warmup: {config.WARMUP_EPOCHS} epochs\")\n",
    "print(f\"Loss weights: Dice={config.DICE_WEIGHT}, CE={config.CE_WEIGHT}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Device: {config.DEVICE}\")\n",
    "print(f\"GPUs available: {num_gpus}\")\n",
    "if num_gpus > 1:\n",
    "    print(\"Multi-GPU training enabled with DataParallel\")\n",
    "    print(f\"Effective batch size: {config.BATCH_SIZE * num_gpus}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f567a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:11.502294Z",
     "iopub.status.busy": "2026-02-03T17:02:11.501921Z",
     "iopub.status.idle": "2026-02-03T17:02:11.526895Z",
     "shell.execute_reply": "2026-02-03T17:02:11.526202Z",
     "shell.execute_reply.started": "2026-02-03T17:02:11.502271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NestedFolderDataset defined!\n"
     ]
    }
   ],
   "source": [
    "class NestedFolderDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir: str, subject_ids: List[str] = None,\n",
    "                 patch_size: Tuple[int, int, int] = (128, 128, 128),\n",
    "                 samples_per_volume: int = 2,\n",
    "                 augment: bool = True):\n",
    "        self.data_dir = data_dir\n",
    "        self.patch_size = patch_size\n",
    "        self.samples_per_volume = samples_per_volume\n",
    "        self.augment = augment\n",
    "\n",
    "        if subject_ids is None:\n",
    "            if os.path.exists(data_dir):\n",
    "                all_items = os.listdir(data_dir)\n",
    "                self.subject_ids = sorted([\n",
    "                    d for d in all_items\n",
    "                    if os.path.isdir(os.path.join(data_dir, d))\n",
    "                ])\n",
    "            else:\n",
    "                self.subject_ids = []\n",
    "        else:\n",
    "            self.subject_ids = subject_ids\n",
    "\n",
    "        print(f\"Found {len(self.subject_ids)} subjects in dataset\")\n",
    "        if len(self.subject_ids) > 0:\n",
    "            print(f\"Sample subjects: {self.subject_ids[:3]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subject_ids) * self.samples_per_volume\n",
    "\n",
    "    def _find_nifti_in_folder(self, folder_path):\n",
    "        \"\"\"Find any .nii or .nii.gz file in a folder.\"\"\"\n",
    "        if not os.path.isdir(folder_path):\n",
    "            return None\n",
    "\n",
    "        all_files = os.listdir(folder_path)\n",
    "        for f in all_files:\n",
    "            if f.endswith('.nii.gz'):\n",
    "                return os.path.join(folder_path, f)\n",
    "        for f in all_files:\n",
    "            if f.endswith('.nii'):\n",
    "                return os.path.join(folder_path, f)\n",
    "        return None\n",
    "\n",
    "    def _find_modality_file(self, patient_path, subject_id, modality):\n",
    "        \"\"\"Find modality file in nested folder structure.\"\"\"\n",
    "        items = os.listdir(patient_path)\n",
    "        modality_lower = modality.lower()\n",
    "\n",
    "        for item in items:\n",
    "            item_path = os.path.join(patient_path, item)\n",
    "            item_lower = item.lower()\n",
    "\n",
    "            if os.path.isdir(item_path):\n",
    "                if modality_lower == 't1':\n",
    "                    if 't1' in item_lower and 't1ce' not in item_lower and 't1gd' not in item_lower:\n",
    "                        nifti_file = self._find_nifti_in_folder(item_path)\n",
    "                        if nifti_file:\n",
    "                            return nifti_file\n",
    "                elif modality_lower in item_lower:\n",
    "                    nifti_file = self._find_nifti_in_folder(item_path)\n",
    "                    if nifti_file:\n",
    "                        return nifti_file\n",
    "\n",
    "        direct_patterns = [\n",
    "            os.path.join(patient_path, f\"{subject_id}_{modality}.nii.gz\"),\n",
    "            os.path.join(patient_path, f\"{subject_id}_{modality}.nii\"),\n",
    "        ]\n",
    "        for pattern in direct_patterns:\n",
    "            if os.path.exists(pattern):\n",
    "                return pattern\n",
    "\n",
    "        raise FileNotFoundError(f\"Could not find {modality} for {subject_id}\")\n",
    "\n",
    "    def _load_nifti(self, filepath):\n",
    "        \"\"\"Load a NIfTI file.\"\"\"\n",
    "        img = nib.load(filepath)\n",
    "        return img.get_fdata().astype(np.float32)\n",
    "\n",
    "    def _normalize(self, data):\n",
    "        \"\"\"Robust Z-score normalization with percentile clipping.\"\"\"\n",
    "        mask = data > 0\n",
    "        if mask.sum() == 0:\n",
    "            return data\n",
    "        pixels = data[mask]\n",
    "        p_low, p_high = np.percentile(pixels, 0.5), np.percentile(pixels, 99.5)\n",
    "        data = np.clip(data, p_low, p_high)\n",
    "        pixels = data[mask]\n",
    "        mean, std = pixels.mean(), pixels.std()\n",
    "        data = (data - mean) / (std + 1e-8)\n",
    "        data[~mask] = 0\n",
    "        return data\n",
    "\n",
    "    def _extract_random_patch(self, volume, seg):\n",
    "        \"\"\"Extract a random patch centered on tumor region (if possible).\"\"\"\n",
    "        D, H, W = volume.shape[1:]\n",
    "        pd, ph, pw = self.patch_size\n",
    "\n",
    "        tumor_coords = np.where(seg > 0)\n",
    "\n",
    "        if len(tumor_coords[0]) > 0 and random.random() > 0.2:\n",
    "            idx = random.randint(0, len(tumor_coords[0]) - 1)\n",
    "            center_d = tumor_coords[0][idx]\n",
    "            center_h = tumor_coords[1][idx]\n",
    "            center_w = tumor_coords[2][idx]\n",
    "\n",
    "            d_start = max(0, min(D - pd, center_d - pd // 2 + random.randint(-20, 20)))\n",
    "            h_start = max(0, min(H - ph, center_h - ph // 2 + random.randint(-20, 20)))\n",
    "            w_start = max(0, min(W - pw, center_w - pw // 2 + random.randint(-20, 20)))\n",
    "        else:\n",
    "            d_start = random.randint(0, max(0, D - pd))\n",
    "            h_start = random.randint(0, max(0, H - ph))\n",
    "            w_start = random.randint(0, max(0, W - pw))\n",
    "\n",
    "        vol_patch = volume[:, d_start:d_start+pd, h_start:h_start+ph, w_start:w_start+pw]\n",
    "        seg_patch = seg[d_start:d_start+pd, h_start:h_start+ph, w_start:w_start+pw]\n",
    "\n",
    "        if vol_patch.shape[1:] != self.patch_size:\n",
    "            pad_d = pd - vol_patch.shape[1]\n",
    "            pad_h = ph - vol_patch.shape[2]\n",
    "            pad_w = pw - vol_patch.shape[3]\n",
    "            vol_patch = np.pad(vol_patch, ((0, 0), (0, pad_d), (0, pad_h), (0, pad_w)))\n",
    "            seg_patch = np.pad(seg_patch, ((0, pad_d), (0, pad_h), (0, pad_w)))\n",
    "\n",
    "        return vol_patch, seg_patch\n",
    "\n",
    "    def _augment(self, volume, seg):\n",
    "        \"\"\"Apply random augmentations.\"\"\"\n",
    "        if random.random() > 0.5:\n",
    "            volume = np.flip(volume, axis=1).copy()\n",
    "            seg = np.flip(seg, axis=0).copy()\n",
    "        if random.random() > 0.5:\n",
    "            volume = np.flip(volume, axis=2).copy()\n",
    "            seg = np.flip(seg, axis=1).copy()\n",
    "        if random.random() > 0.5:\n",
    "            volume = np.flip(volume, axis=3).copy()\n",
    "            seg = np.flip(seg, axis=2).copy()\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            for c in range(volume.shape[0]):\n",
    "                scale = random.uniform(0.9, 1.1)\n",
    "                volume[c] = volume[c] * scale\n",
    "\n",
    "        return volume, seg\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_idx = idx // self.samples_per_volume\n",
    "        subject_id = self.subject_ids[subject_idx]\n",
    "        patient_path = os.path.join(self.data_dir, subject_id)\n",
    "\n",
    "        modalities = ['t1', 't1ce', 't2', 'flair']\n",
    "        modality_data = []\n",
    "\n",
    "        for mod in modalities:\n",
    "            try:\n",
    "                filepath = self._find_modality_file(patient_path, subject_id, mod)\n",
    "                data = self._load_nifti(filepath)\n",
    "                data = self._normalize(data)\n",
    "                modality_data.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {mod} for {subject_id}: {e}\")\n",
    "                if modality_data:\n",
    "                    modality_data.append(np.zeros_like(modality_data[0]))\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        volume = np.stack(modality_data, axis=0)\n",
    "\n",
    "        try:\n",
    "            seg_file = self._find_modality_file(patient_path, subject_id, 'seg')\n",
    "            seg = self._load_nifti(seg_file)\n",
    "            new_seg = np.zeros_like(seg)\n",
    "            new_seg[seg == 1] = 1\n",
    "            new_seg[seg == 2] = 2\n",
    "            new_seg[seg == 4] = 3\n",
    "            seg = new_seg\n",
    "        except:\n",
    "            seg = np.zeros(volume.shape[1:], dtype=np.float32)\n",
    "\n",
    "        vol_patch, seg_patch = self._extract_random_patch(volume, seg)\n",
    "\n",
    "        if self.augment:\n",
    "            vol_patch, seg_patch = self._augment(vol_patch, seg_patch)\n",
    "\n",
    "        return {\n",
    "            'volume': torch.from_numpy(vol_patch.copy()).float(),\n",
    "            'segmentation': torch.from_numpy(seg_patch.copy()).long(),\n",
    "            'subject_id': subject_id\n",
    "        }\n",
    "\n",
    "print(\"NestedFolderDataset defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a841c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:11.529564Z",
     "iopub.status.busy": "2026-02-03T17:02:11.528980Z",
     "iopub.status.idle": "2026-02-03T17:02:12.680232Z",
     "shell.execute_reply": "2026-02-03T17:02:12.679653Z",
     "shell.execute_reply.started": "2026-02-03T17:02:11.529541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ” DATASET STRUCTURE DIAGNOSTIC\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Data directory: /kaggle/input/instant-odc-ai-hackathon/Train\n",
      "ðŸ“Š Total subject folders found: 917\n",
      "\n",
      "ðŸ“‹ Sample subjects: ['BraTS2021_01030', 'BraTS2021_00656', 'BraTS2021_00466', 'BraTS2021_01070', 'BraTS2021_01057']\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ§ª Subject 1: BraTS2021_01030\n",
      "   Contents: ['BraTS2021_01030_t1ce.nii', 'BraTS2021_01030_flair.nii', 'BraTS2021_01030_t2.nii', 'BraTS2021_01030_t1.nii', 'BraTS2021_01030_seg.nii']\n",
      "   âœ… T1     â†’ BraTS2021_01030_t1ce.nii\n",
      "   âœ… T1CE   â†’ BraTS2021_01030_t1ce.nii\n",
      "   âœ… T2     â†’ BraTS2021_01030_t2.nii\n",
      "   âœ… FLAIR  â†’ BraTS2021_01030_flair.nii\n",
      "   âœ… SEG    â†’ BraTS2021_01030_seg.nii\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ§ª Subject 2: BraTS2021_00656\n",
      "   Contents: ['BraTS2021_00656_seg.nii', 'BraTS2021_00656_t1ce.nii', 'BraTS2021_00656_t2.nii', 'BraTS2021_00656_t1.nii', 'BraTS2021_00656_flair.nii']\n",
      "   âœ… T1     â†’ 00000427_brain_t1.nii\n",
      "   âœ… T1CE   â†’ 00000427_brain_t1ce.nii\n",
      "   âœ… T2     â†’ 00000427_brain_t2.nii\n",
      "   âœ… FLAIR  â†’ 00000427_brain_flair.nii\n",
      "   âœ… SEG    â†’ 00000427_final_seg.nii\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ðŸ§ª Subject 3: BraTS2021_00466\n",
      "   Contents: ['BraTS2021_00466_t1.nii', 'BraTS2021_00466_seg.nii', 'BraTS2021_00466_t2.nii', 'BraTS2021_00466_flair.nii', 'BraTS2021_00466_t1ce.nii']\n",
      "   âœ… T1     â†’ 00000139_brain_t1.nii\n",
      "   âœ… T1CE   â†’ 00000139_brain_t1ce.nii\n",
      "   âœ… T2     â†’ 00000139_brain_t2.nii\n",
      "   âœ… FLAIR  â†’ 00000139_brain_flair.nii\n",
      "   âœ… SEG    â†’ 00000139_final_seg.nii\n",
      "\n",
      "============================================================\n",
      "âœ… Dataset structure looks correct!\n",
      "   All modalities found for sampled subjects.\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def diagnose_dataset_structure(data_dir: str, num_samples: int = 2):\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Directory does not exist: {data_dir}\")\n",
    "        return False\n",
    "\n",
    "    all_items = os.listdir(data_dir)\n",
    "    subject_folders = [d for d in all_items if os.path.isdir(os.path.join(data_dir, d))]\n",
    "\n",
    "    print(f\"\\nData directory: {data_dir}\")\n",
    "    print(f\"Total subject folders found: {len(subject_folders)}\")\n",
    "\n",
    "    if len(subject_folders) == 0:\n",
    "        print(\"No subject folders found.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"\\nSample subjects: {subject_folders[:5]}\")\n",
    "\n",
    "    modalities_to_check = ['t1', 't1ce', 't2', 'flair', 'seg']\n",
    "    all_ok = True\n",
    "\n",
    "    for i, subject_id in enumerate(subject_folders[:num_samples]):\n",
    "        print(f\"\\n{'â”€' * 50}\")\n",
    "        print(f\"Subject {i+1}: {subject_id}\")\n",
    "        patient_path = os.path.join(data_dir, subject_id)\n",
    "\n",
    "        contents = os.listdir(patient_path)\n",
    "        print(f\"   Contents: {contents}\")\n",
    "\n",
    "        for mod in modalities_to_check:\n",
    "            found = False\n",
    "            found_path = None\n",
    "\n",
    "            for item in contents:\n",
    "                item_path = os.path.join(patient_path, item)\n",
    "                item_lower = item.lower()\n",
    "\n",
    "                if os.path.isdir(item_path):\n",
    "                    if mod == 't1':\n",
    "                        if 't1' in item_lower and 't1ce' not in item_lower and 't1gd' not in item_lower:\n",
    "                            nii_files = [f for f in os.listdir(item_path) if f.endswith(('.nii.gz', '.nii'))]\n",
    "                            if nii_files:\n",
    "                                found = True\n",
    "                                found_path = os.path.join(item_path, nii_files[0])\n",
    "                                break\n",
    "                    elif mod.lower() in item_lower:\n",
    "                        nii_files = [f for f in os.listdir(item_path) if f.endswith(('.nii.gz', '.nii'))]\n",
    "                        if nii_files:\n",
    "                            found = True\n",
    "                            found_path = os.path.join(item_path, nii_files[0])\n",
    "                            break\n",
    "                elif item.endswith(('.nii.gz', '.nii')):\n",
    "                    if mod.lower() in item.lower():\n",
    "                        found = True\n",
    "                        found_path = item_path\n",
    "                        break\n",
    "\n",
    "            status = \"OK\" if found else \"MISSING\"\n",
    "            if found:\n",
    "                print(f\"   {status:7s} {mod.upper():6s} -> {os.path.basename(found_path)}\")\n",
    "            else:\n",
    "                print(f\"   {status:7s} {mod.upper():6s} -> NOT FOUND\")\n",
    "                all_ok = False\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    if all_ok:\n",
    "        print(\"Dataset structure looks correct.\")\n",
    "        print(\"All modalities found for sampled subjects.\")\n",
    "    else:\n",
    "        print(\"Some modalities were not found.\")\n",
    "        print(\"Check the folder naming conventions.\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return all_ok\n",
    "\n",
    "diagnose_dataset_structure(TrainingConfig.TRAIN_DIR, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56749bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:12.681759Z",
     "iopub.status.busy": "2026-02-03T17:02:12.681186Z",
     "iopub.status.idle": "2026-02-03T17:02:12.695453Z",
     "shell.execute_reply": "2026-02-03T17:02:12.694694Z",
     "shell.execute_reply.started": "2026-02-03T17:02:12.681735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss functions defined!\n"
     ]
    }
   ],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for segmentation.\"\"\"\n",
    "\n",
    "    def __init__(self, smooth: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: Softmax probabilities (B, C, D, H, W)\n",
    "            target: One-hot encoded targets (B, C, D, H, W)\n",
    "        \"\"\"\n",
    "        pred_flat = pred.view(pred.size(0), pred.size(1), -1)\n",
    "        target_flat = target.view(target.size(0), target.size(1), -1)\n",
    "\n",
    "        intersection = (pred_flat * target_flat).sum(-1)\n",
    "        union = pred_flat.sum(-1) + target_flat.sum(-1)\n",
    "\n",
    "        dice = (2 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice[:, 1:].mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined Dice + Cross Entropy loss with region-based Dice.\"\"\"\n",
    "\n",
    "    def __init__(self, dice_weight: float = 0.5, ce_weight: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> dict:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: Logits (B, C, D, H, W), C=4 classes\n",
    "            target: Class indices (B, D, H, W)\n",
    "        \"\"\"\n",
    "        ce = self.ce_loss(pred, target)\n",
    "\n",
    "        pred_soft = F.softmax(pred, dim=1)\n",
    "\n",
    "        target_onehot = F.one_hot(target, num_classes=pred.size(1))\n",
    "        target_onehot = target_onehot.permute(0, 4, 1, 2, 3).float()\n",
    "\n",
    "        dice = self.dice_loss(pred_soft, target_onehot)\n",
    "\n",
    "        pred_wt = pred_soft[:, 1:].sum(dim=1, keepdim=True)\n",
    "        target_wt = (target >= 1).float().unsqueeze(1)\n",
    "\n",
    "        pred_tc = pred_soft[:, 1:2] + pred_soft[:, 3:4]\n",
    "        target_tc = ((target == 1) | (target == 3)).float().unsqueeze(1)\n",
    "\n",
    "        pred_et = pred_soft[:, 3:4]\n",
    "        target_et = (target == 3).float().unsqueeze(1)\n",
    "\n",
    "        def dice_score(p, t, smooth=1e-5):\n",
    "            intersection = (p * t).sum()\n",
    "            return (2 * intersection + smooth) / (p.sum() + t.sum() + smooth)\n",
    "\n",
    "        dice_wt = 1 - dice_score(pred_wt, target_wt)\n",
    "        dice_tc = 1 - dice_score(pred_tc, target_tc)\n",
    "        dice_et = 1 - dice_score(pred_et, target_et)\n",
    "\n",
    "        region_dice = (dice_wt + dice_tc + dice_et) / 3\n",
    "\n",
    "        total = self.ce_weight * ce + self.dice_weight * (dice + region_dice) / 2\n",
    "\n",
    "        return {\n",
    "            'total': total,\n",
    "            'ce': ce.item(),\n",
    "            'dice': dice.item(),\n",
    "            'dice_wt': 1 - dice_wt.item(),\n",
    "            'dice_tc': 1 - dice_tc.item(),\n",
    "            'dice_et': 1 - dice_et.item()\n",
    "        }\n",
    "\n",
    "print(\"Loss functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1394731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:12.697350Z",
     "iopub.status.busy": "2026-02-03T17:02:12.696620Z",
     "iopub.status.idle": "2026-02-03T17:02:15.408355Z",
     "shell.execute_reply": "2026-02-03T17:02:15.407689Z",
     "shell.execute_reply.started": "2026-02-03T17:02:12.697321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading pretrained weights from: /kaggle/input/mednext/pytorch/default/1/best_model.pt\n",
      "âš ï¸ torch.load default failed: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "ðŸ”“ Retrying with weights_only=False (trusted checkpoint assumed)...\n",
      "âœ… Pretrained weights loaded successfully!\n",
      "\n",
      "ðŸ“Š Model Parameter Summary:\n",
      "   Total parameters: 10,526,469 (10.53M)\n",
      "   All parameters trainable (using Differential Learning Rates)\n",
      "\n",
      "ðŸ–¥ï¸ Device: cuda\n",
      "ðŸš€ Using 2 GPUs with DataParallel!\n",
      "âœ… Model ready for fine-tuning with Differential Learning Rates!\n"
     ]
    }
   ],
   "source": [
    "EARLY_LAYER_PATTERNS = ['stem', 'enc_block_0', 'enc_block_1', 'downsample_0', 'downsample_1']\n",
    "EARLY_LR_FACTOR = 0.01\n",
    "\n",
    "def load_pretrained_model(\n",
    "    pretrained_path: str,\n",
    "    model_size: str = 'B',\n",
    "    in_channels: int = 4,\n",
    "    num_classes: int = 4,\n",
    "    kernel_size: int = 3,\n",
    " ):\n",
    "    \"\"\"Load pretrained MedNeXt model (all layers trainable).\"\"\"\n",
    "    model = create_mednext_v1(\n",
    "        num_input_channels=in_channels,\n",
    "        num_classes=num_classes,\n",
    "        model_id=model_size,\n",
    "        kernel_size=kernel_size,\n",
    "        deep_supervision=False\n",
    "    )\n",
    "\n",
    "    if os.path.exists(pretrained_path):\n",
    "        print(f\"Loading pretrained weights from: {pretrained_path}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "        except Exception as e:\n",
    "            print(f\"torch.load default failed: {e}\")\n",
    "            print(\"Retrying with weights_only=False\")\n",
    "            checkpoint = torch.load(pretrained_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "        if isinstance(checkpoint, dict):\n",
    "            if 'state_dict' in checkpoint:\n",
    "                state_dict = checkpoint['state_dict']\n",
    "            elif 'model_state_dict' in checkpoint:\n",
    "                state_dict = checkpoint['model_state_dict']\n",
    "            else:\n",
    "                state_dict = checkpoint\n",
    "        else:\n",
    "            state_dict = checkpoint\n",
    "\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            if k.startswith('module.'):\n",
    "                new_state_dict[k[7:]] = v\n",
    "            else:\n",
    "                new_state_dict[k] = v\n",
    "\n",
    "        model.load_state_dict(new_state_dict, strict=False)\n",
    "        print(\"Pretrained weights loaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Pretrained weights not found at {pretrained_path}\")\n",
    "        print(\"Training from scratch...\")\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"\\nModel Parameter Summary:\")\n",
    "    print(f\"   Total parameters: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
    "    print(\"   All parameters trainable (using differential learning rates)\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_parameter_groups(model, base_lr: float, early_lr_factor: float = 0.01):\n",
    "    \"\"\"Create parameter groups with differential learning rates.\"\"\"\n",
    "    early_lr = base_lr * early_lr_factor\n",
    "\n",
    "    actual_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "\n",
    "    early_params = []\n",
    "    rest_params = []\n",
    "    early_param_names = []\n",
    "    rest_param_names = []\n",
    "\n",
    "    for name, param in actual_model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "\n",
    "        is_early = any(pattern in name for pattern in EARLY_LAYER_PATTERNS)\n",
    "\n",
    "        if is_early:\n",
    "            early_params.append(param)\n",
    "            early_param_names.append(name)\n",
    "        else:\n",
    "            rest_params.append(param)\n",
    "            rest_param_names.append(name)\n",
    "\n",
    "    early_count = sum(p.numel() for p in early_params)\n",
    "    rest_count = sum(p.numel() for p in rest_params)\n",
    "\n",
    "    print(\"\\nDifferential Learning Rate Setup:\")\n",
    "    print(f\"   Early layers (LR={early_lr:.2e}): {len(early_params)} tensors, {early_count:,} params ({early_count/1e6:.2f}M)\")\n",
    "    print(f\"   Later layers (LR={base_lr:.2e}): {len(rest_params)} tensors, {rest_count:,} params ({rest_count/1e6:.2f}M)\")\n",
    "    print(f\"   LR ratio: 1:{int(1/early_lr_factor)}\")\n",
    "\n",
    "    return [\n",
    "        {'params': early_params, 'lr': early_lr, 'name': 'early_layers'},\n",
    "        {'params': rest_params, 'lr': base_lr, 'name': 'later_layers'}\n",
    "    ]\n",
    "\n",
    "\n",
    "model = load_pretrained_model(\n",
    "    pretrained_path=TrainingConfig.PRETRAINED_PATH,\n",
    "    model_size=TrainingConfig.MODEL_SIZE,\n",
    "    in_channels=TrainingConfig.IN_CHANNELS,\n",
    "    num_classes=TrainingConfig.NUM_CLASSES,\n",
    "    kernel_size=TrainingConfig.KERNEL_SIZE,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice: {device}\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model ready for fine-tuning with differential learning rates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330573eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:15.409568Z",
     "iopub.status.busy": "2026-02-03T17:02:15.409329Z",
     "iopub.status.idle": "2026-02-03T17:02:17.473539Z",
     "shell.execute_reply": "2026-02-03T17:02:17.472784Z",
     "shell.execute_reply.started": "2026-02-03T17:02:15.409547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 917 subjects in dataset\n",
      "Sample subjects: ['BraTS2021_00000', 'BraTS2021_00002', 'BraTS2021_00003']\n",
      "\n",
      "ðŸ“Š Train/Validation Split:\n",
      "   Total subjects: 917\n",
      "   Training subjects: 779 (85%)\n",
      "   Validation subjects: 138 (15%)\n",
      "Found 779 subjects in dataset\n",
      "Sample subjects: ['BraTS2021_00044', 'BraTS2021_01061', 'BraTS2021_01328']\n",
      "Found 138 subjects in dataset\n",
      "Sample subjects: ['BraTS2021_01308', 'BraTS2021_01178', 'BraTS2021_00352']\n",
      "\n",
      "ðŸ“Š Dataset Statistics:\n",
      "   Training samples per epoch: 3116\n",
      "   Validation samples per epoch: 138\n",
      "   Patch size: (128, 128, 128)\n",
      "   Batch size: 1\n",
      "   Training batches per epoch: 3116\n",
      "   Validation batches per epoch: 138\n",
      "\n",
      "ðŸ§ª Testing dataset loading...\n",
      "   Volume shape: torch.Size([4, 128, 128, 128])\n",
      "   Segmentation shape: torch.Size([128, 128, 128])\n",
      "   Subject ID: BraTS2021_00044\n",
      "   Label distribution:\n",
      "      Class 0: 2,080,516 voxels (99.21%)\n",
      "      Class 1: 601 voxels (0.03%)\n",
      "      Class 2: 11,200 voxels (0.53%)\n",
      "      Class 3: 4,835 voxels (0.23%)\n",
      "âœ… Dataset loading test passed!\n"
     ]
    }
   ],
   "source": [
    "_temp_dataset = NestedFolderDataset(\n",
    "    data_dir=TrainingConfig.TRAIN_DIR,\n",
    "    patch_size=TrainingConfig.PATCH_SIZE,\n",
    "    samples_per_volume=1,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "all_subjects = _temp_dataset.subject_ids.copy()\n",
    "random.seed(42)\n",
    "random.shuffle(all_subjects)\n",
    "\n",
    "split_idx = int(len(all_subjects) * (1 - TrainingConfig.VAL_SPLIT))\n",
    "train_subjects = all_subjects[:split_idx]\n",
    "val_subjects = all_subjects[split_idx:]\n",
    "\n",
    "print(\"\\nTrain/Validation Split:\")\n",
    "print(f\"   Total subjects: {len(all_subjects)}\")\n",
    "print(f\"   Training subjects: {len(train_subjects)} ({100*(1-TrainingConfig.VAL_SPLIT):.0f}%)\")\n",
    "print(f\"   Validation subjects: {len(val_subjects)} ({100*TrainingConfig.VAL_SPLIT:.0f}%)\")\n",
    "\n",
    "train_dataset = NestedFolderDataset(\n",
    "    data_dir=TrainingConfig.TRAIN_DIR,\n",
    "    subject_ids=train_subjects,\n",
    "    patch_size=TrainingConfig.PATCH_SIZE,\n",
    "    samples_per_volume=TrainingConfig.SAMPLES_PER_VOLUME,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = NestedFolderDataset(\n",
    "    data_dir=TrainingConfig.TRAIN_DIR,\n",
    "    subject_ids=val_subjects,\n",
    "    patch_size=TrainingConfig.PATCH_SIZE,\n",
    "    samples_per_volume=1,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(f\"   Training samples per epoch: {len(train_dataset)}\")\n",
    "print(f\"   Validation samples per epoch: {len(val_dataset)}\")\n",
    "print(f\"   Patch size: {TrainingConfig.PATCH_SIZE}\")\n",
    "print(f\"   Batch size: {TrainingConfig.BATCH_SIZE}\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TrainingConfig.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=TrainingConfig.NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TrainingConfig.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=TrainingConfig.NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"   Training batches per epoch: {len(train_loader)}\")\n",
    "print(f\"   Validation batches per epoch: {len(val_loader)}\")\n",
    "\n",
    "if len(train_dataset) > 0:\n",
    "    print(\"\\nTesting dataset loading...\")\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"   Volume shape: {sample['volume'].shape}\")\n",
    "    print(f\"   Segmentation shape: {sample['segmentation'].shape}\")\n",
    "    print(f\"   Subject ID: {sample['subject_id']}\")\n",
    "\n",
    "    seg = sample['segmentation']\n",
    "    unique, counts = torch.unique(seg, return_counts=True)\n",
    "    print(\"   Label distribution:\")\n",
    "    for u, c in zip(unique.tolist(), counts.tolist()):\n",
    "        pct = 100 * c / seg.numel()\n",
    "        print(f\"      Class {u}: {c:,} voxels ({pct:.2f}%)\")\n",
    "\n",
    "    print(\"Dataset loading test passed.\")\n",
    "else:\n",
    "    print(\"No subjects found in training directory.\")\n",
    "\n",
    "del _temp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643237b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:17.475139Z",
     "iopub.status.busy": "2026-02-03T17:02:17.474567Z",
     "iopub.status.idle": "2026-02-03T17:02:20.123033Z",
     "shell.execute_reply": "2026-02-03T17:02:20.122291Z",
     "shell.execute_reply.started": "2026-02-03T17:02:17.475109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Differential Learning Rate Setup:\n",
      "   Early layers (LR=1.00e-06): 34 tensors, 63,968 params (0.06M)\n",
      "   Later layers (LR=1.00e-04): 195 tensors, 10,462,501 params (10.46M)\n",
      "   LR ratio: 1:100 (later layers train 100x faster)\n",
      "\n",
      "âœ… Optimizer configured with Differential Learning Rates!\n",
      "   Later layers LR: 1.00e-04\n",
      "   Early layers LR: 1.00e-06 (100x smaller)\n",
      "   Warmup epochs: 2\n",
      "   Total epochs: 10\n",
      "   Weight decay: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/615104050.py:65: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "param_groups = get_parameter_groups(\n",
    "    model,\n",
    "    base_lr=TrainingConfig.LEARNING_RATE,\n",
    "    early_lr_factor=EARLY_LR_FACTOR\n",
    ")\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    param_groups,\n",
    "    weight_decay=TrainingConfig.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "def get_lr_with_warmup(epoch: int, batch_idx: int, total_batches: int) -> float:\n",
    "    \"\"\"Calculate learning rate multiplier with linear warmup then cosine decay.\"\"\"\n",
    "    warmup_epochs = TrainingConfig.WARMUP_EPOCHS\n",
    "\n",
    "    current_step = epoch * total_batches + batch_idx\n",
    "    warmup_steps = warmup_epochs * total_batches\n",
    "\n",
    "    if current_step < warmup_steps:\n",
    "        return current_step / warmup_steps\n",
    "    else:\n",
    "        progress = (epoch - warmup_epochs) / max(1, TrainingConfig.NUM_EPOCHS - warmup_epochs)\n",
    "        return (1 + math.cos(math.pi * progress)) / 2\n",
    "\n",
    "def set_lr_with_differential(optimizer, lr_multiplier: float, base_lr: float, early_lr_factor: float):\n",
    "    \"\"\"Set learning rate for parameter groups, maintaining the differential ratio.\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group.get('name') == 'early_layers':\n",
    "            param_group['lr'] = base_lr * early_lr_factor * lr_multiplier\n",
    "        else:\n",
    "            param_group['lr'] = base_lr * lr_multiplier\n",
    "\n",
    "criterion = CombinedLoss(\n",
    "    dice_weight=TrainingConfig.DICE_WEIGHT,\n",
    "    ce_weight=TrainingConfig.CE_WEIGHT\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"Optimizer configured with differential learning rates.\")\n",
    "print(f\"   Later layers LR: {TrainingConfig.LEARNING_RATE:.2e}\")\n",
    "print(f\"   Early layers LR: {TrainingConfig.LEARNING_RATE * EARLY_LR_FACTOR:.2e}\")\n",
    "print(f\"   Warmup epochs: {TrainingConfig.WARMUP_EPOCHS}\")\n",
    "print(f\"   Total epochs: {TrainingConfig.NUM_EPOCHS}\")\n",
    "print(f\"   Weight decay: {TrainingConfig.WEIGHT_DECAY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271b20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:20.124739Z",
     "iopub.status.busy": "2026-02-03T17:02:20.124270Z",
     "iopub.status.idle": "2026-02-03T17:02:20.139401Z",
     "shell.execute_reply": "2026-02-03T17:02:20.138492Z",
     "shell.execute_reply.started": "2026-02-03T17:02:20.124715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training & Validation loops defined with Differential Learning Rates!\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    scaler: GradScaler,\n",
    "    epoch: int,\n",
    "    device: torch.device\n",
    ") -> dict:\n",
    "    \"\"\"Train for one epoch with differential learning rates.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    epoch_metrics = {\n",
    "        'loss': [],\n",
    "        'ce': [],\n",
    "        'dice': [],\n",
    "        'dice_wt': [],\n",
    "        'dice_tc': [],\n",
    "        'dice_et': []\n",
    "    }\n",
    "\n",
    "    total_batches = len(train_loader)\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{TrainingConfig.NUM_EPOCHS} [Train]\")\n",
    "\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        lr_multiplier = get_lr_with_warmup(epoch, batch_idx, total_batches)\n",
    "        set_lr_with_differential(\n",
    "            optimizer,\n",
    "            lr_multiplier,\n",
    "            TrainingConfig.LEARNING_RATE,\n",
    "            EARLY_LR_FACTOR\n",
    "        )\n",
    "\n",
    "        current_lr = TrainingConfig.LEARNING_RATE * lr_multiplier\n",
    "\n",
    "        volumes = batch['volume'].to(device)\n",
    "        targets = batch['segmentation'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(volumes)\n",
    "            losses = criterion(outputs, targets)\n",
    "            loss = losses['total']\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_metrics['loss'].append(loss.item())\n",
    "        epoch_metrics['ce'].append(losses['ce'])\n",
    "        epoch_metrics['dice'].append(losses['dice'])\n",
    "        epoch_metrics['dice_wt'].append(losses['dice_wt'])\n",
    "        epoch_metrics['dice_tc'].append(losses['dice_tc'])\n",
    "        epoch_metrics['dice_et'].append(losses['dice_et'])\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'dice_wt': f\"{losses['dice_wt']:.4f}\",\n",
    "            'lr': f\"{current_lr:.2e}\",\n",
    "            'grad_norm': f\"{grad_norm:.2f}\"\n",
    "        })\n",
    "\n",
    "    avg_metrics = {k: np.mean(v) for k, v in epoch_metrics.items()}\n",
    "    return avg_metrics\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "    model: nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "    epoch: int\n",
    ") -> dict:\n",
    "    \"\"\"Validate for one epoch (no gradient computation).\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    val_metrics = {\n",
    "        'loss': [],\n",
    "        'ce': [],\n",
    "        'dice': [],\n",
    "        'dice_wt': [],\n",
    "        'dice_tc': [],\n",
    "        'dice_et': []\n",
    "    }\n",
    "\n",
    "    pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{TrainingConfig.NUM_EPOCHS} [Val]\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        volumes = batch['volume'].to(device)\n",
    "        targets = batch['segmentation'].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(volumes)\n",
    "            losses = criterion(outputs, targets)\n",
    "\n",
    "        val_metrics['loss'].append(losses['total'].item())\n",
    "        val_metrics['ce'].append(losses['ce'])\n",
    "        val_metrics['dice'].append(losses['dice'])\n",
    "        val_metrics['dice_wt'].append(losses['dice_wt'])\n",
    "        val_metrics['dice_tc'].append(losses['dice_tc'])\n",
    "        val_metrics['dice_et'].append(losses['dice_et'])\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{losses['total'].item():.4f}\",\n",
    "            'dice_wt': f\"{losses['dice_wt']:.4f}\",\n",
    "            'dice_et': f\"{losses['dice_et']:.4f}\"\n",
    "        })\n",
    "\n",
    "    avg_metrics = {k: np.mean(v) for k, v in val_metrics.items()}\n",
    "    return avg_metrics\n",
    "\n",
    "def compute_dice_score(pred: torch.Tensor, target: torch.Tensor, smooth: float = 1e-5) -> float:\n",
    "    \"\"\"Compute Dice score between prediction and target.\"\"\"\n",
    "    pred_flat = pred.flatten()\n",
    "    target_flat = target.flatten()\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    return float((2 * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth))\n",
    "\n",
    "print(\"Training and validation loops defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4c4cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T17:02:20.141775Z",
     "iopub.status.busy": "2026-02-03T17:02:20.141551Z",
     "iopub.status.idle": "2026-02-03T17:02:53.406148Z",
     "shell.execute_reply": "2026-02-03T17:02:53.405162Z",
     "shell.execute_reply.started": "2026-02-03T17:02:20.141755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸš€ STARTING FINE-TUNING WITH VALIDATION\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Training data: /kaggle/input/instant-odc-ai-hackathon/Train\n",
      "ðŸ“ Pretrained weights: /kaggle/input/mednext/pytorch/default/1/best_model.pt\n",
      "ðŸ“ Output path: /kaggle/working/best_finetuned_model.pt\n",
      "\n",
      "âš™ï¸ Training Configuration:\n",
      "   Epochs: 10\n",
      "   Warmup epochs: 2\n",
      "   Batch size: 1 (effective: 2)\n",
      "   Later layers LR: 1.00e-04\n",
      "   Early layers LR: 1.00e-06 (100x smaller)\n",
      "   Strategy: Differential Learning Rates (all layers trainable)\n",
      "\n",
      "ðŸ“Š Data Split:\n",
      "   Training subjects: 779\n",
      "   Validation subjects: 138\n",
      "   Validation split: 15%\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“… Epoch 1/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]:   0%|          | 0/3116 [00:00<?, ?it/s]/tmp/ipykernel_55/4163948662.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/10 [Train]:   1%|          | 30/3116 [00:33<56:58,  1.11s/it, loss=0.0579, dice_wt=0.9763, lr=4.65e-07, grad_norm=0.31] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_55/656145346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m# 2. Re-run this cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRESUME_CHECKPOINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_55/656145346.py\u001b[0m in \u001b[0;36mmain_training\u001b[0;34m(resume_from)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# ===== TRAINING PHASE =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         train_metrics = train_one_epoch(\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_55/4163948662.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, scaler, epoch, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RESUME_CHECKPOINT = None\n",
    "\n",
    "def load_checkpoint_for_resume(checkpoint_path: str, model, optimizer):\n",
    "    \"\"\"Load checkpoint to resume training after a timeout.\"\"\"\n",
    "    print(f\"\\nResuming from checkpoint: {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model.module.load_state_dict(state_dict)\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    if 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"Optimizer state restored\")\n",
    "\n",
    "    start_epoch = checkpoint.get('epoch', 0)\n",
    "    best_val_dice = checkpoint.get('best_val_dice', checkpoint.get('best_dice', 0.0))\n",
    "    history = checkpoint.get('history', {\n",
    "        'epoch': [],\n",
    "        'train_loss': [], 'train_dice_wt': [], 'train_dice_tc': [], 'train_dice_et': [],\n",
    "        'val_loss': [], 'val_dice_wt': [], 'val_dice_tc': [], 'val_dice_et': [],\n",
    "        'lr': []\n",
    "    })\n",
    "\n",
    "    print(f\"Resuming from epoch {start_epoch + 1}\")\n",
    "    print(f\"Best validation Dice so far: {best_val_dice:.4f}\")\n",
    "\n",
    "    return start_epoch, best_val_dice, history\n",
    "\n",
    "\n",
    "def main_training(resume_from: str = None):\n",
    "    \"\"\"Main training loop with validation-based model selection and checkpointing.\"\"\"\n",
    "    global model, optimizer\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"STARTING FINE-TUNING WITH VALIDATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nTraining data: {TrainingConfig.TRAIN_DIR}\")\n",
    "    print(f\"Pretrained weights: {TrainingConfig.PRETRAINED_PATH}\")\n",
    "    print(f\"Output path: {TrainingConfig.OUTPUT_MODEL_PATH}\")\n",
    "    print(f\"\\nTraining Configuration:\")\n",
    "    print(f\"   Epochs: {TrainingConfig.NUM_EPOCHS}\")\n",
    "    print(f\"   Warmup epochs: {TrainingConfig.WARMUP_EPOCHS}\")\n",
    "    print(f\"   Batch size: {TrainingConfig.BATCH_SIZE} (effective: {TrainingConfig.BATCH_SIZE * max(1, torch.cuda.device_count())})\")\n",
    "    print(f\"   Later layers LR: {TrainingConfig.LEARNING_RATE:.2e}\")\n",
    "    print(f\"   Early layers LR: {TrainingConfig.LEARNING_RATE * EARLY_LR_FACTOR:.2e} (100x smaller)\")\n",
    "    print(\"   Strategy: Differential Learning Rates (all layers trainable)\")\n",
    "    print(f\"\\nData Split:\")\n",
    "    print(f\"   Training subjects: {len(train_dataset.subject_ids)}\")\n",
    "    print(f\"   Validation subjects: {len(val_dataset.subject_ids)}\")\n",
    "    print(f\"   Validation split: {TrainingConfig.VAL_SPLIT*100:.0f}%\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_dice = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'train_dice_wt': [],\n",
    "        'train_dice_tc': [],\n",
    "        'train_dice_et': [],\n",
    "        'val_loss': [],\n",
    "        'val_dice_wt': [],\n",
    "        'val_dice_tc': [],\n",
    "        'val_dice_et': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    if resume_from and os.path.exists(resume_from):\n",
    "        start_epoch, best_val_dice, history = load_checkpoint_for_resume(\n",
    "            resume_from, model, optimizer\n",
    "        )\n",
    "        best_epoch = start_epoch\n",
    "    elif resume_from:\n",
    "        print(f\"Resume checkpoint not found: {resume_from}\")\n",
    "        print(\"Starting from scratch...\")\n",
    "\n",
    "    for epoch in range(start_epoch, TrainingConfig.NUM_EPOCHS):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{TrainingConfig.NUM_EPOCHS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        train_metrics = train_one_epoch(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            epoch=epoch,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        val_metrics = validate_one_epoch(\n",
    "            model=model,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            epoch=epoch\n",
    "        )\n",
    "\n",
    "        current_lr = get_lr_with_warmup(epoch, len(train_loader) - 1, len(train_loader))\n",
    "\n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['train_loss'].append(train_metrics['loss'])\n",
    "        history['train_dice_wt'].append(train_metrics['dice_wt'])\n",
    "        history['train_dice_tc'].append(train_metrics['dice_tc'])\n",
    "        history['train_dice_et'].append(train_metrics['dice_et'])\n",
    "        history['val_loss'].append(val_metrics['loss'])\n",
    "        history['val_dice_wt'].append(val_metrics['dice_wt'])\n",
    "        history['val_dice_tc'].append(val_metrics['dice_tc'])\n",
    "        history['val_dice_et'].append(val_metrics['dice_et'])\n",
    "        history['lr'].append(current_lr)\n",
    "\n",
    "        val_avg_dice = (val_metrics['dice_wt'] + val_metrics['dice_tc'] + val_metrics['dice_et']) / 3\n",
    "        train_avg_dice = (train_metrics['dice_wt'] + train_metrics['dice_tc'] + train_metrics['dice_et']) / 3\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "        print(f\"   {'Metric':<12} {'Train':>10} {'Val':>10}\")\n",
    "        print(f\"   {'-'*34}\")\n",
    "        print(f\"   {'Loss':<12} {train_metrics['loss']:>10.4f} {val_metrics['loss']:>10.4f}\")\n",
    "        print(f\"   {'Dice WT':<12} {train_metrics['dice_wt']:>10.4f} {val_metrics['dice_wt']:>10.4f}\")\n",
    "        print(f\"   {'Dice TC':<12} {train_metrics['dice_tc']:>10.4f} {val_metrics['dice_tc']:>10.4f}\")\n",
    "        print(f\"   {'Dice ET':<12} {train_metrics['dice_et']:>10.4f} {val_metrics['dice_et']:>10.4f}\")\n",
    "        print(f\"   {'Avg Dice':<12} {train_avg_dice:>10.4f} {val_avg_dice:>10.4f}\")\n",
    "        print(f\"   LR: {current_lr:.2e}\")\n",
    "\n",
    "        if isinstance(model, nn.DataParallel):\n",
    "            state_dict = model.module.state_dict()\n",
    "        else:\n",
    "            state_dict = model.state_dict()\n",
    "\n",
    "        if val_avg_dice > best_val_dice:\n",
    "            best_val_dice = val_avg_dice\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': state_dict,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict(),\n",
    "                'best_val_dice': best_val_dice,\n",
    "                'history': history,\n",
    "                'config': {\n",
    "                    'model_size': TrainingConfig.MODEL_SIZE,\n",
    "                    'in_channels': TrainingConfig.IN_CHANNELS,\n",
    "                    'num_classes': TrainingConfig.NUM_CLASSES,\n",
    "                    'kernel_size': TrainingConfig.KERNEL_SIZE,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            torch.save(checkpoint, TrainingConfig.OUTPUT_MODEL_PATH)\n",
    "            print(f\"New best model saved (Val Dice: {best_val_dice:.4f})\")\n",
    "        else:\n",
    "            print(f\"Val Dice did not improve (best: {best_val_dice:.4f} at epoch {best_epoch})\")\n",
    "\n",
    "        checkpoint_path = TrainingConfig.OUTPUT_MODEL_PATH.replace('.pt', f'_epoch{epoch+1}.pt')\n",
    "        epoch_checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': state_dict,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scaler_state_dict': scaler.state_dict(),\n",
    "            'best_val_dice': best_val_dice,\n",
    "            'history': history,\n",
    "        }\n",
    "        torch.save(epoch_checkpoint, checkpoint_path)\n",
    "        print(f\"Epoch checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINE-TUNING COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"   Best Epoch: {best_epoch}\")\n",
    "    print(f\"   Best Validation Dice: {best_val_dice:.4f}\")\n",
    "    print(f\"   Model saved to: {TrainingConfig.OUTPUT_MODEL_PATH}\")\n",
    "\n",
    "    import json\n",
    "    history_path = TrainingConfig.OUTPUT_MODEL_PATH.replace('.pt', '_history.json')\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    print(f\"   History saved to: {history_path}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "history = main_training(resume_from=RESUME_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8035cdc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-03T17:02:53.407177Z",
     "iopub.status.idle": "2026-02-03T17:02:53.407426Z",
     "shell.execute_reply": "2026-02-03T17:02:53.407324Z",
     "shell.execute_reply.started": "2026-02-03T17:02:53.407310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history: dict):\n",
    "    \"\"\"Plot training and validation metrics over epochs.\"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(history['epoch'], history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    ax1.plot(history['epoch'], history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training vs Validation Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(history['epoch'], history['train_dice_wt'], 'r-', label='Train WT', linewidth=1.5, alpha=0.7)\n",
    "    ax2.plot(history['epoch'], history['train_dice_tc'], 'g-', label='Train TC', linewidth=1.5, alpha=0.7)\n",
    "    ax2.plot(history['epoch'], history['train_dice_et'], 'b-', label='Train ET', linewidth=1.5, alpha=0.7)\n",
    "    ax2.plot(history['epoch'], history['val_dice_wt'], 'r--o', label='Val WT', linewidth=2, markersize=5)\n",
    "    ax2.plot(history['epoch'], history['val_dice_tc'], 'g--s', label='Val TC', linewidth=2, markersize=5)\n",
    "    ax2.plot(history['epoch'], history['val_dice_et'], 'b--^', label='Val ET', linewidth=2, markersize=5)\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Dice Score')\n",
    "    ax2.set_title('Region Dice Scores (Train vs Val)')\n",
    "    ax2.legend(loc='lower right', fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim([0, 1])\n",
    "\n",
    "    ax3 = axes[1, 0]\n",
    "    train_avg_dice = [(wt + tc + et) / 3 for wt, tc, et in\n",
    "                      zip(history['train_dice_wt'], history['train_dice_tc'], history['train_dice_et'])]\n",
    "    val_avg_dice = [(wt + tc + et) / 3 for wt, tc, et in\n",
    "                    zip(history['val_dice_wt'], history['val_dice_tc'], history['val_dice_et'])]\n",
    "\n",
    "    ax3.plot(history['epoch'], train_avg_dice, 'b-o', label='Train Avg Dice', linewidth=2, markersize=5)\n",
    "    ax3.plot(history['epoch'], val_avg_dice, 'r-s', label='Val Avg Dice', linewidth=2, markersize=5)\n",
    "\n",
    "    best_val_idx = np.argmax(val_avg_dice)\n",
    "    best_val_epoch = history['epoch'][best_val_idx]\n",
    "    best_val_score = val_avg_dice[best_val_idx]\n",
    "    ax3.axvline(x=best_val_epoch, color='green', linestyle='--', alpha=0.7, label=f'Best Val (Epoch {best_val_epoch})')\n",
    "    ax3.scatter([best_val_epoch], [best_val_score], s=200, c='green', marker='*', zorder=5)\n",
    "\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Average Dice Score')\n",
    "    ax3.set_title('Average Dice Score (Train vs Val)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_ylim([0, 1])\n",
    "\n",
    "    ax3.fill_between(history['epoch'], train_avg_dice, val_avg_dice, alpha=0.2, color='gray')\n",
    "\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "\n",
    "    best_epoch = history['epoch'][best_val_idx]\n",
    "\n",
    "    summary_text = f\"\"\"\n",
    "\n",
    "    Model saved to:\n",
    "    {TrainingConfig.OUTPUT_MODEL_PATH}\n",
    "    \"\"\"\n",
    "\n",
    "    ax4.text(0.1, 0.5, summary_text, transform=ax4.transAxes, fontsize=11,\n",
    "             verticalalignment='center', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training history plot saved to: training_history.png\")\n",
    "\n",
    "if 'history' in dir() and history is not None:\n",
    "    plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91fed3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-03T17:02:53.408897Z",
     "iopub.status.idle": "2026-02-03T17:02:53.409599Z",
     "shell.execute_reply": "2026-02-03T17:02:53.409437Z",
     "shell.execute_reply.started": "2026-02-03T17:02:53.409412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_finetuned_model(checkpoint_path: str, device: torch.device):\n",
    "    \"\"\"Load the fine-tuned model for inference.\"\"\"\n",
    "\n",
    "    print(f\"Loading fine-tuned model from: {checkpoint_path}\")\n",
    "\n",
    "    model = create_mednext_v1(\n",
    "        num_input_channels=TrainingConfig.IN_CHANNELS,\n",
    "        num_classes=TrainingConfig.NUM_CLASSES,\n",
    "        model_id=TrainingConfig.MODEL_SIZE,\n",
    "        kernel_size=TrainingConfig.KERNEL_SIZE,\n",
    "        deep_supervision=False\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        print(f\"Loaded from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "        print(f\"Best Dice: {checkpoint.get('best_dice', 'unknown')}\")\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_state_dict[k[7:]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Fine-tuned model loaded and ready for inference.\")\n",
    "    return model\n",
    "\n",
    "# Example:\n",
    "# finetuned_model = load_finetuned_model(TrainingConfig.OUTPUT_MODEL_PATH, device)\n",
    "\n",
    "print(\"Inference loading function defined.\")\n",
    "print(\"To load the fine-tuned model for inference, run:\")\n",
    "print(f\"  finetuned_model = load_finetuned_model('{TrainingConfig.OUTPUT_MODEL_PATH}', device)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15542776,
     "sourceId": 129601,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 576416,
     "modelInstanceId": 563906,
     "sourceId": 739319,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
