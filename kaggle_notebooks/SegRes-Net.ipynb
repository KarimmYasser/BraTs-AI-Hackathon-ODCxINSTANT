{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SegResNet for Brain Tumor Segmentation\n",
        "\n",
        "This notebook implements a complete training pipeline for brain tumor segmentation using the BraTS 2021 dataset with a SegResNet architecture.\n",
        "\n",
        "## Contents\n",
        "1. Imports and Setup\n",
        "2. Data Loading\n",
        "3. Data Preprocessing\n",
        "4. Dataset and DataLoader\n",
        "5. Loss Functions\n",
        "6. SegResNet Model Architecture\n",
        "7. Training Loop\n",
        "8. Inference and Visualization\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1. Imports and Setup\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Data Loading\n",
        "\n",
        "Load the BraTS dataset and create a DataFrame with file paths.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/kaggle/input/brain-tumor-segmentation-hackathon\"\n",
        "\n",
        "def resolve_path(patient_path, modality_name):\n",
        "    \"\"\"Find the exact .nii file for a modality.\"\"\"\n",
        "    try:\n",
        "        entries = os.listdir(patient_path)\n",
        "    except OSError:\n",
        "        return None\n",
        "\n",
        "    for e in entries:\n",
        "        if modality_name == 't1' and 't1ce' in e:\n",
        "            continue\n",
        "        if modality_name in e.lower():\n",
        "            full_path = os.path.join(patient_path, e)\n",
        "            if os.path.isfile(full_path) and full_path.endswith('.nii.gz'):\n",
        "                return full_path\n",
        "            elif os.path.isdir(full_path):\n",
        "                for f in os.listdir(full_path):\n",
        "                    if f.endswith('.nii.gz'):\n",
        "                        return os.path.join(full_path, f)\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_brats_file_paths(root_dir):\n",
        "    \"\"\"Index all patient folders and return a DataFrame with file paths.\"\"\"\n",
        "    data_list = []\n",
        "    \n",
        "    for item in os.listdir(root_dir):\n",
        "        item_path = os.path.join(root_dir, item)\n",
        "        if not os.path.isdir(item_path):\n",
        "            continue\n",
        "        \n",
        "        # Handle nested structure\n",
        "        patient_dirs = []\n",
        "        for sub_item in os.listdir(item_path):\n",
        "            sub_path = os.path.join(item_path, sub_item)\n",
        "            if os.path.isdir(sub_path):\n",
        "                patient_dirs.append(sub_path)\n",
        "        \n",
        "        if not patient_dirs:\n",
        "            patient_dirs = [item_path]\n",
        "        \n",
        "        for patient_path in patient_dirs:\n",
        "            patient_id = os.path.basename(patient_path)\n",
        "            paths = {'id': patient_id}\n",
        "            \n",
        "            for modality in ['flair', 't1', 't1ce', 't2', 'seg']:\n",
        "                path = resolve_path(patient_path, modality)\n",
        "                if path:\n",
        "                    paths[modality] = path\n",
        "            \n",
        "            if len(paths) == 6:\n",
        "                data_list.append(paths)\n",
        "    \n",
        "    print(f\"Found {len(data_list)} patients\")\n",
        "    return pd.DataFrame(data_list)\n",
        "\n",
        "df = get_brats_file_paths(DATA_ROOT)\n",
        "print(df.head())"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3. Data Preprocessing\n",
        "\n",
        "Functions for volume normalization, cropping, and patch extraction.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_volume(volume):\n",
        "    \"\"\"Robust Z-Score Normalization.\"\"\"\n",
        "    mask = volume > 0\n",
        "    if np.sum(mask) == 0:\n",
        "        return volume\n",
        "\n",
        "    pixels = volume[mask]\n",
        "    p_low, p_high = np.percentile(pixels, 0.5), np.percentile(pixels, 99.5)\n",
        "    volume = np.clip(volume, p_low, p_high)\n",
        "    \n",
        "    pixels = volume[mask]\n",
        "    mean, std = pixels.mean(), pixels.std()\n",
        "    volume = (volume - mean) / (std + 1e-8)\n",
        "    volume[~mask] = 0\n",
        "    \n",
        "    return volume\n",
        "\n",
        "\n",
        "def crop_to_bbox(image_stack, label):\n",
        "    \"\"\"Crop to the bounding box of non-zero signal.\"\"\"\n",
        "    mask = np.sum(image_stack, axis=0) > 0\n",
        "    coords = np.argwhere(mask)\n",
        "    \n",
        "    if len(coords) == 0:\n",
        "        return image_stack, label\n",
        "\n",
        "    x_min, y_min, z_min = coords.min(axis=0)\n",
        "    x_max, y_max, z_max = coords.max(axis=0) + 1\n",
        "\n",
        "    return (image_stack[:, x_min:x_max, y_min:y_max, z_min:z_max], \n",
        "            label[x_min:x_max, y_min:y_max, z_min:z_max])\n",
        "\n",
        "\n",
        "def get_random_patch(image, label, patch_size=(128, 128, 128)):\n",
        "    \"\"\"Extract a random patch with foreground sampling.\"\"\"\n",
        "    c, h, w, d = image.shape\n",
        "    ph, pw, pd = patch_size\n",
        "\n",
        "    pad_h, pad_w, pad_d = max(ph-h, 0), max(pw-w, 0), max(pd-d, 0)\n",
        "    if pad_h or pad_w or pad_d:\n",
        "        image = np.pad(image, ((0, 0), (0, pad_h), (0, pad_w), (0, pad_d)), mode='constant')\n",
        "        label = np.pad(label, ((0, pad_h), (0, pad_w), (0, pad_d)), mode='constant')\n",
        "        h, w, d = image.shape[1:]\n",
        "\n",
        "    if np.random.rand() < 0.33:\n",
        "        fg_coords = np.argwhere(label > 0)\n",
        "        if len(fg_coords) > 0:\n",
        "            center = fg_coords[np.random.randint(len(fg_coords))]\n",
        "            x = np.clip(center[0] - ph // 2, 0, h - ph)\n",
        "            y = np.clip(center[1] - pw // 2, 0, w - pw)\n",
        "            z = np.clip(center[2] - pd // 2, 0, d - pd)\n",
        "            return image[:, x:x+ph, y:y+pw, z:z+pd], label[x:x+ph, y:y+pw, z:z+pd]\n",
        "    \n",
        "    x = np.random.randint(0, h - ph + 1)\n",
        "    y = np.random.randint(0, w - pw + 1)\n",
        "    z = np.random.randint(0, d - pd + 1)\n",
        "    \n",
        "    return image[:, x:x+ph, y:y+pw, z:z+pd], label[x:x+ph, y:y+pw, z:z+pd]"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4. Dataset and DataLoader\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class BratsDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for BraTS data.\"\"\"\n",
        "    def __init__(self, df, phase=\"train\", augment=False):\n",
        "        self.df = df\n",
        "        self.phase = phase\n",
        "        self.augment = augment\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        t1 = normalize_volume(nib.load(row['t1']).get_fdata().astype(np.float32))\n",
        "        t1ce = normalize_volume(nib.load(row['t1ce']).get_fdata().astype(np.float32))\n",
        "        t2 = normalize_volume(nib.load(row['t2']).get_fdata().astype(np.float32))\n",
        "        flair = normalize_volume(nib.load(row['flair']).get_fdata().astype(np.float32))\n",
        "        seg = nib.load(row['seg']).get_fdata().astype(np.int64)\n",
        "        \n",
        "        seg[seg == 4] = 3\n",
        "        \n",
        "        image = np.stack([t1, t1ce, t2, flair], axis=0)\n",
        "        image, seg = crop_to_bbox(image, seg)\n",
        "        image, seg = get_random_patch(image, seg, patch_size=(128, 128, 128))\n",
        "        \n",
        "        if self.augment and self.phase == \"train\":\n",
        "            if np.random.rand() > 0.5:\n",
        "                image = np.flip(image, axis=1).copy()\n",
        "                seg = np.flip(seg, axis=0).copy()\n",
        "        \n",
        "        return torch.from_numpy(image), torch.from_numpy(seg)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(f\"Training: {len(train_df)}, Validation: {len(val_df)}\")\n",
        "\n",
        "# Create datasets and loaders\n",
        "BATCH_SIZE = 2\n",
        "train_ds = BratsDataset(train_df, phase=\"train\", augment=True)\n",
        "val_ds = BratsDataset(val_df, phase=\"val\", augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Loss Functions\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Multi-class Dice Loss for segmentation.\"\"\"\n",
        "    def __init__(self, smooth=1e-5):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        probs = F.softmax(inputs, dim=1)\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=inputs.shape[1])\n",
        "        targets_one_hot = targets_one_hot.permute(0, 4, 1, 2, 3).float()\n",
        "\n",
        "        dims = (0, 2, 3, 4)\n",
        "        intersection = torch.sum(probs * targets_one_hot, dims)\n",
        "        cardinality = torch.sum(probs + targets_one_hot, dims)\n",
        "        \n",
        "        dice_score = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
        "        return 1. - dice_score.mean()\n",
        "\n",
        "\n",
        "class DiceCELoss(nn.Module):\n",
        "    \"\"\"Combined Dice and Cross-Entropy Loss.\"\"\"\n",
        "    def __init__(self, weight_ce=1.0, weight_dice=1.0):\n",
        "        super().__init__()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.dice = DiceLoss()\n",
        "        self.weight_ce = weight_ce\n",
        "        self.weight_dice = weight_dice\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        loss_ce = self.ce(inputs, targets.long())\n",
        "        loss_dice = self.dice(inputs, targets)\n",
        "        return self.weight_ce * loss_ce + self.weight_dice * loss_dice"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6. SegResNet Model Architecture\n",
        "\n",
        "SegResNet uses residual blocks for better gradient flow in deep networks.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual block that learns the difference instead of raw mapping.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        \n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm3d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x += residual\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SegResNet(nn.Module):\n",
        "    \"\"\"SegResNet for volumetric segmentation.\"\"\"\n",
        "    def __init__(self, in_channels=4, out_channels=4, init_filters=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, init_filters, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(init_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.res_block1 = ResidualBlock(init_filters, init_filters)\n",
        "        self.res_block2 = ResidualBlock(init_filters, init_filters * 2, stride=2)\n",
        "        self.res_block3 = ResidualBlock(init_filters * 2, init_filters * 4, stride=2)\n",
        "        self.res_block4 = ResidualBlock(init_filters * 4, init_filters * 8, stride=2)\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.bottleneck = ResidualBlock(init_filters * 8, init_filters * 16, stride=2)\n",
        "        \n",
        "        # Decoder\n",
        "        self.up4 = nn.ConvTranspose3d(init_filters * 16, init_filters * 8, kernel_size=2, stride=2)\n",
        "        self.dec4 = ResidualBlock(init_filters * 16, init_filters * 8)\n",
        "        \n",
        "        self.up3 = nn.ConvTranspose3d(init_filters * 8, init_filters * 4, kernel_size=2, stride=2)\n",
        "        self.dec3 = ResidualBlock(init_filters * 8, init_filters * 4)\n",
        "        \n",
        "        self.up2 = nn.ConvTranspose3d(init_filters * 4, init_filters * 2, kernel_size=2, stride=2)\n",
        "        self.dec2 = ResidualBlock(init_filters * 4, init_filters * 2)\n",
        "        \n",
        "        self.up1 = nn.ConvTranspose3d(init_filters * 2, init_filters, kernel_size=2, stride=2)\n",
        "        self.dec1 = ResidualBlock(init_filters * 2, init_filters)\n",
        "        \n",
        "        self.final = nn.Conv3d(init_filters, out_channels, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x1 = self.enc1(x)\n",
        "        x1 = self.res_block1(x1)\n",
        "        x2 = self.res_block2(x1)\n",
        "        x3 = self.res_block3(x2)\n",
        "        x4 = self.res_block4(x3)\n",
        "        \n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(x4)\n",
        "        \n",
        "        # Decoder with skip connections\n",
        "        u4 = self.up4(b)\n",
        "        if u4.shape != x4.shape:\n",
        "            u4 = F.interpolate(u4, size=x4.shape[2:])\n",
        "        d4 = torch.cat((u4, x4), dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "        \n",
        "        u3 = self.up3(d4)\n",
        "        if u3.shape != x3.shape:\n",
        "            u3 = F.interpolate(u3, size=x3.shape[2:])\n",
        "        d3 = torch.cat((u3, x3), dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "        \n",
        "        u2 = self.up2(d3)\n",
        "        if u2.shape != x2.shape:\n",
        "            u2 = F.interpolate(u2, size=x2.shape[2:])\n",
        "        d2 = torch.cat((u2, x2), dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "        \n",
        "        u1 = self.up1(d2)\n",
        "        if u1.shape != x1.shape:\n",
        "            u1 = F.interpolate(u1, size=x1.shape[2:])\n",
        "        d1 = torch.cat((u1, x1), dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "        \n",
        "        return self.final(d1)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7. Training Loop\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_brats_dice(predictions, masks):\n",
        "    \"\"\"Compute Dice Score for BraTS regions: WT, TC, ET.\"\"\"\n",
        "    preds_argmax = torch.argmax(predictions, dim=1)\n",
        "    \n",
        "    dice_scores = {'WT': 0.0, 'TC': 0.0, 'ET': 0.0}\n",
        "    batch_size = preds_argmax.shape[0]\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        pred = preds_argmax[i]\n",
        "        mask = masks[i]\n",
        "        \n",
        "        pred_wt = (pred > 0).float()\n",
        "        mask_wt = (mask > 0).float()\n",
        "        \n",
        "        pred_tc = ((pred == 1) | (pred == 3)).float()\n",
        "        mask_tc = ((mask == 1) | (mask == 3)).float()\n",
        "        \n",
        "        pred_et = (pred == 3).float()\n",
        "        mask_et = (mask == 3).float()\n",
        "        \n",
        "        def dice(p, m, smooth=1e-5):\n",
        "            intersection = (p * m).sum()\n",
        "            return (2. * intersection + smooth) / (p.sum() + m.sum() + smooth)\n",
        "        \n",
        "        dice_scores['WT'] += dice(pred_wt, mask_wt).item()\n",
        "        dice_scores['TC'] += dice(pred_tc, mask_tc).item()\n",
        "        dice_scores['ET'] += dice(pred_et, mask_et).item()\n",
        "    \n",
        "    return {k: v / batch_size for k, v in dice_scores.items()}"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "EPOCHS = 20\n",
        "SAVE_PATH = \"segresnet_best.pth\"\n",
        "\n",
        "# Initialize\n",
        "model = SegResNet(in_channels=4, out_channels=4, init_filters=32).to(DEVICE)\n",
        "criterion = DiceCELoss(weight_ce=1.0, weight_dice=1.0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    \n",
        "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for images, masks in progress:\n",
        "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        progress.set_postfix({\"loss\": loss.item()})\n",
        "    \n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    dice_wt, dice_tc, dice_et = 0.0, 0.0, 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, masks).item()\n",
        "            \n",
        "            dice = compute_brats_dice(outputs, masks)\n",
        "            dice_wt += dice['WT']\n",
        "            dice_tc += dice['TC']\n",
        "            dice_et += dice['ET']\n",
        "    \n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    dice_wt /= len(val_loader)\n",
        "    dice_tc /= len(val_loader)\n",
        "    dice_et /= len(val_loader)\n",
        "    \n",
        "    scheduler.step(avg_val_loss)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
        "    print(f\"         Dice WT={dice_wt:.4f}, TC={dice_tc:.4f}, ET={dice_et:.4f}\")\n",
        "    \n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(f\"         Model saved!\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8. Inference and Visualization\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_prediction(model, loader, device=DEVICE):\n",
        "    \"\"\"Visualize model predictions alongside ground truth.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    images, masks = next(iter(loader))\n",
        "    images = images.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predictions = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
        "    \n",
        "    images = images.cpu().numpy()\n",
        "    masks = masks.numpy()\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    \n",
        "    sample_idx = 0\n",
        "    slice_idx = images.shape[4] // 2\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    \n",
        "    modalities = ['T1', 'T1ce', 'T2', 'FLAIR']\n",
        "    for i, name in enumerate(modalities):\n",
        "        axes[0, i].imshow(np.rot90(images[sample_idx, i, :, :, slice_idx]), cmap='gray')\n",
        "        axes[0, i].set_title(name)\n",
        "        axes[0, i].axis('off')\n",
        "    \n",
        "    axes[1, 0].imshow(np.rot90(masks[sample_idx, :, :, slice_idx]), cmap='jet', vmin=0, vmax=3)\n",
        "    axes[1, 0].set_title('Ground Truth')\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    axes[1, 1].imshow(np.rot90(predictions[sample_idx, :, :, slice_idx]), cmap='jet', vmin=0, vmax=3)\n",
        "    axes[1, 1].set_title('Prediction')\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    axes[1, 2].axis('off')\n",
        "    axes[1, 3].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize\n",
        "visualize_prediction(model, val_loader)"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}